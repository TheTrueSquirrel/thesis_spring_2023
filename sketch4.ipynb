{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Request data from USGS and save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Set the API endpoint URL\n",
    "url = 'https://earthquake.usgs.gov/fdsnws/event/1/query'\n",
    "\n",
    "# Define the bounding box for the area of interest\n",
    "min_latitude = 10\n",
    "max_latitude = 60\n",
    "min_longitude = 134 #117 is wide\n",
    "max_longitude = 174 #165 more tight\n",
    "\n",
    "# Create an empty list to hold the earthquake data\n",
    "earthquakes = []\n",
    "\n",
    "for year in range(1973, 2023):\n",
    "    for month in range(1, 13):\n",
    "        # Set the parameters for the API request\n",
    "        starttime = f'{year}-{month:02d}-01'\n",
    "        endtime = f'{year}-{month+1:02d}-01'\n",
    "        if month == 12:\n",
    "            endtime = f'{year+1}-01-01'\n",
    "        params = {\n",
    "            'format': 'geojson',\n",
    "            'starttime': starttime,\n",
    "            'endtime': endtime,\n",
    "            'minmagnitude': '0',\n",
    "            'maxmagnitude': '10',\n",
    "            'minlatitude': min_latitude,\n",
    "            'maxlatitude': max_latitude,\n",
    "            'minlongitude': min_longitude,\n",
    "            'maxlongitude': max_longitude,\n",
    "            'mindepth': '0',\n",
    "            'maxdepth': '1000',\n",
    "        }\n",
    "\n",
    "        # Send the API request and get the response\n",
    "        response = requests.get(url, params=params)\n",
    "\n",
    "        # Parse the JSON response\n",
    "        data = response.json()\n",
    "\n",
    "        # Extract the data for each earthquake and append it to the list\n",
    "        for feature in data['features']:\n",
    "            longitude = feature['geometry']['coordinates'][0]\n",
    "            latitude = feature['geometry']['coordinates'][1]\n",
    "            time = pd.to_datetime(feature['properties']['time'], unit='ms')\n",
    "            magnitude = feature['properties']['mag']\n",
    "            depth = feature['geometry']['coordinates'][2]\n",
    "            focal_mechanism = feature['properties']['types'][0]\n",
    "            earthquake = {'Longitude': longitude, 'Latitude': latitude, 'Time': time, 'Magnitude': magnitude, 'Depth': depth}\n",
    "            earthquakes.append(earthquake)\n",
    "# Create a DataFrame from the list of earthquake data\n",
    "df = pd.DataFrame(earthquakes)\n",
    "\n",
    "# Cut off magnitudes of 0\n",
    "df = df[df.Magnitude > 0]\n",
    "\n",
    "# save as csv\n",
    "# df.to_csv('data/Japan_10_60_134_174_1973_2023_V2.csv')\n",
    "\n",
    "# Print the first few rows of the DataFrame\n",
    "print(df.head())\n",
    "print(df.shape, df.Magnitude.min())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform CSV to 3D numpy array (where D3 are bins of magnitude) and save .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load earthquake data\n",
    "data = pd.read_csv('data/Japan_10_60_134_174_1973_2023.csv')\n",
    "\n",
    "# Define area of interest\n",
    "min_lon = 134\n",
    "max_lon = 174\n",
    "min_lat = 10\n",
    "max_lat = 60\n",
    "\n",
    "# Define time window size (1 week in this case)\n",
    "window_size = timedelta(weeks=1)\n",
    "\n",
    "# Calculate number of time windows\n",
    "data['Time'] = pd.to_datetime(data.Time)\n",
    "start_time = data['Time'].min()\n",
    "end_time = data['Time'].max()\n",
    "num_time_windows = (end_time - start_time) // window_size + 1\n",
    "\n",
    "# Define spatial bin size (2 degrees in this case)\n",
    "bin_size = 2\n",
    "\n",
    "# Calculate number of spatial bins\n",
    "num_lon_bins = int((max_lon - min_lon) / bin_size)\n",
    "num_lat_bins = int((max_lat - min_lat) / bin_size)\n",
    "num_bins = num_lon_bins * num_lat_bins\n",
    "\n",
    "# Define magnitude bin size and number of bins\n",
    "num_mag_bins = 10\n",
    "\n",
    "# Create tensor with zeros\n",
    "tensor = np.zeros((num_bins, num_time_windows, num_mag_bins), dtype=int)\n",
    "\n",
    "# Iterate over time windows\n",
    "for i in range(num_time_windows):\n",
    "    # Get earthquake data within current time window\n",
    "    mask = (data['Time'] >= start_time) & (data['Time'] < start_time + window_size)\n",
    "    window_data = data.loc[mask]\n",
    "\n",
    "    # Iterate over spatial bins\n",
    "    for lon in range(min_lon, max_lon, bin_size):\n",
    "        for lat in range(min_lat, max_lat, bin_size):\n",
    "            # Get earthquake data within current spatial bin\n",
    "            bin_data = window_data[(window_data['Longitude'] >= lon) & (window_data['Longitude'] < lon + bin_size) & \n",
    "                                   (window_data['Latitude'] >= lat) & (window_data['Latitude'] < lat + bin_size)]\n",
    "\n",
    "            \n",
    "            # Bin magnitudes between 0 and 10 and count number of earthquakes in each bin\n",
    "            magnitudes = bin_data['Magnitude']\n",
    "            counts, _ = np.histogram(magnitudes, bins=np.linspace(0, 10, num_mag_bins+1))\n",
    "\n",
    "            # Store counts in tensor\n",
    "            bin_idx = (lon - min_lon)//bin_size*num_lat_bins + (lat - min_lat)//bin_size\n",
    "            tensor[bin_idx, i, :] = counts\n",
    "    \n",
    "    # Increment time window\n",
    "    start_time += window_size\n",
    "\n",
    "\n",
    "# Print tensor shape\n",
    "np.save('data/Japan_10_60_134_174_1973_2023.npy',tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert CSV to 2D numpy array where rows are 2x2 degrees pixels and columns are bins of time of a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load earthquake data\n",
    "data = pd.read_csv('data/Japan_10_60_134_174_1973_2023.csv')\n",
    "\n",
    "# Define area of interest\n",
    "min_lon = 134\n",
    "max_lon = 174\n",
    "min_lat = 10\n",
    "max_lat = 60\n",
    "\n",
    "# Define time window size (1 day in this case)\n",
    "window_size = timedelta(days=1)\n",
    "\n",
    "# Calculate number of time windows\n",
    "data['Time'] = pd.to_datetime(data.Time)\n",
    "start_time = data['Time'].min()\n",
    "end_time = data['Time'].max()\n",
    "num_time_windows = (end_time - start_time) // window_size + 1\n",
    "\n",
    "# Define spatial bin size (2 degrees in this case)\n",
    "bin_size = 2\n",
    "\n",
    "# Calculate number of spatial bins\n",
    "num_lon_bins = int((max_lon - min_lon) / bin_size)\n",
    "num_lat_bins = int((max_lat - min_lat) / bin_size)\n",
    "num_bins = num_lon_bins * num_lat_bins\n",
    "\n",
    "# Create tensor with zeros\n",
    "tensor = np.zeros((num_bins, num_time_windows))\n",
    "\n",
    "# Iterate over time windows\n",
    "for i in range(num_time_windows):\n",
    "    # Get earthquake data within current time window\n",
    "    mask = (data['Time'] >= start_time) & (data['Time'] < start_time + window_size)\n",
    "    window_data = data.loc[mask]\n",
    "\n",
    "    # Iterate over spatial bins\n",
    "    for lon in range(min_lon, max_lon, bin_size):\n",
    "        for lat in range(min_lat, max_lat, bin_size):\n",
    "            # Get earthquake data within current spatial bin\n",
    "            bin_data = window_data[(window_data['Longitude'] >= lon) & (window_data['Longitude'] < lon + bin_size) & \n",
    "                                   (window_data['Latitude'] >= lat) & (window_data['Latitude'] < lat + bin_size)]\n",
    "\n",
    "            # Check if there are any earthquakes in the current bin\n",
    "            if not bin_data.empty:\n",
    "                # Find the maximum magnitude in the current bin\n",
    "                max_mag = bin_data['Magnitude'].max()\n",
    "\n",
    "                # Store maximum magnitude in tensor\n",
    "                bin_idx = (lon - min_lon)//bin_size*num_lat_bins + (lat - min_lat)//bin_size\n",
    "                tensor[bin_idx, i] = max_mag\n",
    "    \n",
    "    # Increment time window\n",
    "    start_time += window_size\n",
    "\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load earthquake data\n",
    "data = pd.read_csv('data/Japan_10_60_134_174_1973_2023.csv')\n",
    "\n",
    "# Define area of interest\n",
    "min_lon = 134\n",
    "max_lon = 174\n",
    "min_lat = 10\n",
    "max_lat = 60\n",
    "\n",
    "# Define time window size (1 day in this case)\n",
    "window_size = timedelta(days=1)\n",
    "\n",
    "# Calculate number of time windows\n",
    "data['Time'] = pd.to_datetime(data.Time)\n",
    "start_time = data['Time'].min()\n",
    "end_time = data['Time'].max()\n",
    "num_time_windows = (end_time - start_time) // window_size + 1\n",
    "\n",
    "# Define spatial bin size (2 degrees in this case)\n",
    "bin_size = 5\n",
    "\n",
    "# Calculate number of spatial bins\n",
    "num_lon_bins = int((max_lon - min_lon) / bin_size)\n",
    "num_lat_bins = int((max_lat - min_lat) / bin_size)\n",
    "num_bins = num_lon_bins * num_lat_bins\n",
    "\n",
    "# Create tensor with zeros\n",
    "tensor = np.zeros((num_bins, num_time_windows))\n",
    "\n",
    "# Create DataFrame to store bin information\n",
    "bins_df = pd.DataFrame(columns=['Longitude', 'Latitude'])\n",
    "\n",
    "# Iterate over spatial bins\n",
    "for lon in range(min_lon, max_lon, bin_size):\n",
    "    for lat in range(min_lat, max_lat, bin_size):\n",
    "        # Add bin information to DataFrame\n",
    "        bins_df = pd.concat([bins_df, pd.DataFrame({'Longitude': lon, 'Latitude': lat}, index=[0])], ignore_index=True)\n",
    "\n",
    "\n",
    "# Iterate over time windows\n",
    "for i in range(num_time_windows):\n",
    "    # Get earthquake data within current time window\n",
    "    mask = (data['Time'] >= start_time) & (data['Time'] < start_time + window_size)\n",
    "    window_data = data.loc[mask]\n",
    "\n",
    "    # Iterate over spatial bins\n",
    "    for j in range(num_bins):\n",
    "        lon = bins_df.loc[j, 'Longitude']\n",
    "        lat = bins_df.loc[j, 'Latitude']\n",
    "        \n",
    "        # Get earthquake data within current spatial bin\n",
    "        bin_data = window_data[(window_data['Longitude'] >= lon) & (window_data['Longitude'] < lon + bin_size) & \n",
    "                               (window_data['Latitude'] >= lat) & (window_data['Latitude'] < lat + bin_size)]\n",
    "\n",
    "        # Check if there are any earthquakes in the current bin\n",
    "        if not bin_data.empty:\n",
    "            # Find the maximum magnitude in the current bin\n",
    "            max_mag = bin_data['Magnitude'].max()\n",
    "\n",
    "            # Store maximum magnitude in tensor\n",
    "            bin_idx = j\n",
    "            tensor[bin_idx, i] = max_mag\n",
    "\n",
    "    # Increment time window\n",
    "    start_time += window_size\n",
    "\n",
    "# Add longitude and latitude columns to DataFrame\n",
    "bins_df['Longitude'] += bin_size/2\n",
    "bins_df['Latitude'] += bin_size/2\n",
    "\n",
    "print(bins_df.head())\n",
    "print(tensor.shape)\n",
    "df = pd.concat((pd.DataFrame(tensor), bins_df), axis=1)\n",
    "# df.to_csv('data/Japan_10_60_134_174_D_5X5_1973_2023.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot earthquake magnitudes on map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as crs\n",
    "import cartopy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "df = pd.read_csv('data/Japan_10_60_134_174_1973_2023_V2.csv').sort_values('Magnitude')\n",
    "# Create a map using Cartopy to display earthquake data with magnitudes, longitude, and latitude\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=crs.Mercator())\n",
    "ax.add_feature(cartopy.feature.LAND, facecolor=[.8,.8,.8])\n",
    "ax.add_feature(cartopy.feature.OCEAN, facecolor=[.95,.95,.95])\n",
    "ax.add_feature(cartopy.feature.COASTLINE,linewidth=0.3)\n",
    "ax.add_feature(cartopy.feature.BORDERS, linestyle=':',linewidth=0.3)\n",
    "\n",
    "# Add gridlines\n",
    "lon = np.linspace(-180,180,181)\n",
    "lat = np.linspace(-90,90,91)\n",
    "\n",
    "gl = ax.gridlines(draw_labels=True)\n",
    "gl.xlocator = mticker.FixedLocator(lon)\n",
    "gl.ylocator = mticker.FixedLocator(lat)\n",
    "gl.top_labels = gl.right_labels = False\n",
    "gl.rotate_labels = True\n",
    "#gl.xlabel_style = {'rotation': 45}\n",
    "\n",
    "# Add coastlines\n",
    "ax.coastlines(color='black', linewidth=0.5)\n",
    "\n",
    "# Plot the earthquake data as scatter points\n",
    "sc = ax.scatter(df['Longitude'], df['Latitude'], c=df['Magnitude'], cmap=\"inferno\", s=np.exp(df['Magnitude'])/100, transform=crs.PlateCarree())\n",
    "\n",
    "# Set the colorbar and its label\n",
    "cbar = fig.colorbar(sc, ax=ax, fraction=0.04, pad=0.02)\n",
    "cbar.set_label('Magnitude')\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "ax.set_title('Earthquakes between 1973 and 2023')\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "# Set the bounds of the map to the minimum and maximum longitude and latitude values\n",
    "# Determine the minimum and maximum longitude and latitude values\n",
    "min_lon, max_lon = df['Longitude'].min(), df['Longitude'].max()\n",
    "min_lat, max_lat = df['Latitude'].min(), df['Latitude'].max()\n",
    "ax.set_extent([min_lon, max_lon, min_lat, max_lat], crs=crs.PlateCarree())\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot earthquake magnitudes over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df['Time'] = pd.to_datetime(df.Time)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "plt.scatter(df.Time, df.Magnitude, s=.1)\n",
    "plt.ylabel('Magnitude')\n",
    "plt.xlabel('Year')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot earthquake depth over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df['Time'] = pd.to_datetime(df.Time)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "plt.scatter(df.Time, df.Depth, s=.1)\n",
    "plt.ylabel('Magnitude')\n",
    "plt.xlabel('Year')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot 2D histogram of amount of earthquakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/Japan_10_60_134_174_1973_2023_V2.csv')\n",
    "df['Time'] = pd.to_datetime(df.Time)\n",
    "df = df.set_index('Time')\n",
    "df = df.sort_index()\n",
    "\n",
    "sns.set(rc={'figure.figsize':(4.8,6)})\n",
    "g = sns.histplot(\n",
    "    df, x=\"Longitude\", y=\"Latitude\",\n",
    "    bins=(20,25), cbar=True)\n",
    "\n",
    "g.set_xticks(ticks=np.linspace(134, 174, 21), labels=np.linspace(134, 174, 21).astype(int), rotation = 90)\n",
    "\n",
    "g.set_yticks(ticks=np.linspace(10, 60, 26), labels=np.linspace(10, 60, 26).astype(int))\n",
    "sns.set(rc={'figure.figsize':(8,8)})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the most active 2x2 area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('data/Japan_10_60_134_174_1973_2023_V2.csv')\n",
    "df['Time'] = pd.to_datetime(df.Time)\n",
    "pixel = df[(df.Longitude > 140) & (df.Longitude < 142) & (df.Latitude > 36) & (df.Latitude < 38)]\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "plt.scatter(pixel.Time, pixel.Magnitude, s=.1)\n",
    "plt.ylabel('Magnitude')\n",
    "plt.xlabel('Year')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot distribution of earthquakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(\n",
    "    data=df, x=\"Magnitude\", y=\"Depth\", s=1, marginal_ticks=True, marginal_kws=dict(bins=74)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot correlation between pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/Japan_10_60_134_174_D_1973_2023.csv').iloc[:,:-2]\n",
    "df = df[(df > 0).any(axis=1)]\n",
    "df = df.rolling(14,axis=1, center=True, min_periods=0).mean()\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.matshow(np.corrcoef(df),0, cmap='seismic',vmin=-1, vmax=1)\n",
    "plt.xlabel(\"2x2 grid pixel\")\n",
    "plt.ylabel(\"2x2 grid pixel\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement ARIMA on 10x10 pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# load earthquake data for a specific area\n",
    "data = pd.read_csv('data/Japan_10_60_134_174_1973_2023_V2.csv')\n",
    "data['Time'] = pd.to_datetime(data.Time)\n",
    "data = data[(data.Longitude > 140) & (data.Longitude < 145) & (data.Latitude > 35) & (data.Latitude < 40)]\n",
    "data.set_index('Time', inplace=True)\n",
    "data = data['Magnitude'].resample('M').max()  # resample by day and get the maximum magnitude of the day\n",
    "data = data.fillna(0)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# fit an ARIMA model to get the summary\n",
    "model = ARIMA(data, order=(3, 0, 3))  # (p, d, q) order\n",
    "model_fit = model.fit()\n",
    "print(model_fit.summary())\n",
    "\"\"\"\n",
    "\n",
    "train_size = 12 * 2\n",
    "total_splits = len(data)-train_size\n",
    "test_size = 1\n",
    "\n",
    "cv = TimeSeriesSplit(n_splits=total_splits, max_train_size=train_size ,test_size=test_size)\n",
    "\n",
    "mae_total = 0\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "mag = 6\n",
    "\n",
    "for train_index, test_index in cv.split(data):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "    # fit an ARIMA model\n",
    "    model = ARIMA(data[train_index], order=(1, 1, 0))  # (p, d, q) order\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    # forecast next week's magnitudes\n",
    "    forecast = model_fit.forecast(steps=test_size)\n",
    "    # print('true:', data[test_index][0], 'prediction:', round(forecast[0],1))\n",
    "\n",
    "    # evaluate model performance\n",
    "    mae = mean_absolute_error(data[test_index], forecast)\n",
    "    mae_total += mae\n",
    "    #print('inermediate MSE:', mse)\n",
    "\n",
    "    if data[test_index][0] >= mag:\n",
    "        y_true.append(1)\n",
    "        if forecast[0] >= mag:\n",
    "            y_pred.append(1)\n",
    "            TP += 1\n",
    "        if forecast[0] < mag:\n",
    "            FN += 1\n",
    "            y_pred.append(0)\n",
    "    if data[test_index][0] < mag:\n",
    "        y_true.append(0)\n",
    "        if forecast[0] >= mag:\n",
    "            y_pred.append(1)\n",
    "            FP += 1\n",
    "        if forecast[0] < mag:\n",
    "            y_pred.append(0)\n",
    "            TN += 1\n",
    "\n",
    "acc = (TP+TN) / (TP+TN+FP+FN)\n",
    "precision = TP / (TP+FP)\n",
    "recall = TP / (TP+FN)\n",
    "specificity = TN / (TN+FP)\n",
    "\n",
    "print('accuracy:', acc)\n",
    "print('precision:', precision)\n",
    "print('recall:', recall)\n",
    "print('specificity:', specificity)\n",
    "print('Mean Absolute Error:', mae_total/total_splits)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "class_names = ['M<6','M>=6']\n",
    "\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualise ACF to define MA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acf_val = acf(data)\n",
    "plt.bar(range(0,len(acf_val)),acf_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize PACF to define AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacf_val = pacf(data)\n",
    "plt.bar(range(0,len(pacf_val)),pacf_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise distribution of magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('data/Japan_10_60_134_174_D_5X5_1973_2023.csv').iloc[:,:-2]\n",
    "print(np.unique(df))\n",
    "print(\"mean:\", np.mean(np.array(df)[df > 0]))\n",
    "\n",
    "X = 6\n",
    "print(\"percentage of values bigger than X:\", (np.array(df) >= X).sum() / len(np.array(df).flatten()))\n",
    "sns.histplot(np.array(df).flatten(), bins=90, log_scale=(False,True))\n",
    "plt.xlabel('Magnitude')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of earthquake magnitudes')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 2d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Choose frequency and binsize\n",
    "freq = 'M'\n",
    "binsize = 5\n",
    "\n",
    "# Load earthquake data into a pandas DataFrame\n",
    "df = pd.read_csv('data/Japan_10_60_134_174_1973_2023_V2.csv')\n",
    "df['Time'] = pd.to_datetime(df.Time)\n",
    "df = df.set_index('Time')\n",
    "df = df.sort_index()\n",
    "\n",
    "# Bin the longitude and latitude values into 2x2 degree bins\n",
    "df['Longitude_bin'] = pd.cut(df['Longitude'], bins=np.arange(134, 175, binsize))\n",
    "df['Latitude_bin'] = pd.cut(df['Latitude'], bins=np.arange(10, 61, binsize))\n",
    "\n",
    "# Group the data by longitude bin, latitude bin, and day, and compute the maximum magnitude within each group\n",
    "grouped = df.groupby(['Longitude_bin', 'Latitude_bin', pd.Grouper(freq=freq, level='Time')])['Magnitude'].max()\n",
    "\n",
    "# Convert the resulting data to a DataFrame, filling missing values with 0\n",
    "grouped_df = grouped.unstack().fillna(0)\n",
    "\n",
    "# Reshape the resulting data into a tensor with shape (1, time, rows, cols, channels)\n",
    "time = len(grouped_df.columns)\n",
    "rows = len(grouped_df.index.levels[0])\n",
    "cols = len(grouped_df.index.levels[1])\n",
    "dataset = np.zeros((1, time, rows, cols, 1))\n",
    "\n",
    "for t in range(time):\n",
    "    dataset[0, t, :, :, 0] = grouped_df.iloc[:, t].values.reshape(rows, cols)\n",
    "\n",
    "# Rotate dimensions corresponding to 20 and 25, 90 degrees anti-clockwise\n",
    "dataset = np.transpose(dataset, axes=(0, 1, 3, 2, 4))\n",
    "dataset = np.flip(dataset, axis=2)\n",
    "\n",
    "dataset = dataset.reshape((dataset.shape[1], -1))\n",
    "dataset = dataset[:, dataset.any(axis=0)]\n",
    "# Print the shape of the resulting tensor\n",
    "print(dataset.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "# define magnitude cutoff\n",
    "mag = 4.5\n",
    "mag_select = (dataset >= mag)\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "# split data in train en test set\n",
    "train, test = train_test_split(dataset, test_size=.3, shuffle=False, random_state=43)\n",
    "mag_train, mag_test = train_test_split(mag_select, test_size=.3, shuffle=False, random_state=43)\n",
    "\n",
    "# define generator\n",
    "n_features = dataset.shape[1]\n",
    "n_input = 10\n",
    "steps_epoch = 32\n",
    "train_generator = TimeseriesGenerator(train, mag_train.astype(int), length=n_input, batch_size=(len(train) - n_input) // steps_epoch, shuffle=False)\n",
    "test_generator = TimeseriesGenerator(test, mag_test.astype(int), length=n_input, batch_size=(len(test) - n_input) // steps_epoch, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate one step problem with lstm\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import LSTM, Dense, Flatten, Input, TimeDistributed, Dropout, RepeatVector, BatchNormalization\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "#########################\n",
    "\"\"\"\n",
    "input= Input(shape=(n_input, n_features))\n",
    "\n",
    "lstm1 = LSTM(12,return_state=True)\n",
    "LSTM_output, state_h, state_c = lstm1(input) \n",
    "states = [state_h, state_c]\n",
    "\n",
    "repeat=RepeatVector(1)\n",
    "LSTM_output = repeat(LSTM_output)\n",
    "\n",
    "lstm2 = LSTM(12,return_sequences=True)\n",
    "all_state_h = lstm2(LSTM_output,initial_state=states)\n",
    "\n",
    "\n",
    "dense = TimeDistributed(Dense(n_features, activation='sigmoid'))\n",
    "output = dense(all_state_h)\n",
    "model_LSTM_return_state = Model(input,output,name='model_LSTM_return_state')\n",
    "\n",
    "model_LSTM_return_state.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "########################\n",
    "#\n",
    "encoder_inputs = Input(shape=(n_input, n_features))\n",
    "encoder_outputs1 = LSTM(12,return_sequences = True, return_state=True, activation='tanh')(encoder_inputs)\n",
    "encoder_states1 = encoder_outputs1[1:]\n",
    "encoder_outputs2 = LSTM(12, return_state=True, activation='tanh')(encoder_outputs1[0])\n",
    "\n",
    "encoder_states2 = encoder_outputs2[1:]\n",
    "#\n",
    "decoder_inputs = RepeatVector(1)(encoder_outputs2[0])\n",
    "#\n",
    "decoder_l1 = LSTM(12, return_sequences=True, activation='tanh')(decoder_inputs,initial_state = encoder_states1)\n",
    "decoder_l2 = LSTM(12, return_sequences=True, activation='tanh')(decoder_l1,initial_state = encoder_states2)\n",
    "decoder_outputs2 = TimeDistributed(Dense(n_features, activation='sigmoid'))(decoder_l2)\n",
    "#\n",
    "model = Model(encoder_inputs,decoder_outputs2)\n",
    "#\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy')\n",
    "print(model.summary())\n",
    "\"\"\"\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(12, activation='tanh', return_sequences=True, input_shape=(n_input, n_features)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(12, activation='tanh', return_sequences=True, input_shape=(n_input, n_features)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(12, activation='tanh', input_shape=(n_input, n_features)))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(n_features, activation='sigmoid'))\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[keras.metrics.Precision(), keras.metrics.Recall(), 'accuracy'])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping\n",
    "callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "# fit model\n",
    "history = model.fit(train_generator, validation_data=test_generator, steps_per_epoch=steps_epoch, epochs=1000, verbose=1, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_generator)\n",
    "\n",
    "y_pred = scaler.inverse_transform(y_pred)\n",
    "y_test = scaler.inverse_transform(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test[:-n_input].flatten() >= mag, y_pred.flatten() >= .5)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test[:-n_input].flatten() >= mag, y_pred.flatten() >= .5)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test[:-n_input].flatten() >= mag, y_pred.flatten() >= .5)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test[:-n_input].flatten() >= mag, y_pred.flatten() >= .5)\n",
    "print('F1 score: %f' % f1)\n",
    "\n",
    "class_names = ['M<6', 'M>=6']\n",
    "\n",
    "print(classification_report(y_test[:-n_input].flatten() >= mag, y_pred.flatten() >= .5, target_names=class_names))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "p = sns.heatmap(confusion_matrix(y_test[:-n_input].flatten() >= mag, y_pred.flatten() >= .5), annot=True, fmt='g')\n",
    "p.set_xlabel(\"Predicted\")\n",
    "p.set_ylabel(\"True\")\n",
    "p.xaxis.set_ticklabels(['M<6', 'M>6'], ha=\"center\", va=\"center\")\n",
    "p.yaxis.set_ticklabels(['M<6', 'M>6'], rotation=0, va=\"center\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def plot_ROC_AUC(X,y):\n",
    "\n",
    "    # Use the trained model to predict the class probabilities for the validation set\n",
    "    y_prob = model.predict(X)\n",
    "    y_pred = scaler.inverse_transform(y_prob)\n",
    "    y_test = scaler.inverse_transform(y)\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr, tpr, _ = roc_curve(y_test[:-n_input].flatten() >= mag, y_pred.flatten())\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot micro-average ROC curve\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = {0:0.2f})'\n",
    "            ''.format(roc_auc), color='blue', linewidth=2)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve (Test)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    # plt.savefig(savefig)\n",
    "    plt.show()\n",
    "\n",
    "plot_ROC_AUC(test_generator, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvLSTM2D"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 5D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Choose frequency and binsize\n",
    "freq = 'M'  # Change frequency to days\n",
    "binsize = 5\n",
    "depthsize = 10\n",
    "# Load earthquake data into a pandas DataFrame\n",
    "df = pd.read_csv('data/Japan_10_60_134_174_1973_2023_V2.csv')\n",
    "df['Time'] = pd.to_datetime(df.Time)\n",
    "df = df.set_index('Time')\n",
    "df = df.sort_index()\n",
    "\n",
    "# Bin the longitude and latitude values into 2x2 degree bins\n",
    "df['Longitude_bin'] = pd.cut(df['Longitude'], bins=np.arange(134, 175, binsize))  # Change bin size to 2 degrees\n",
    "df['Latitude_bin'] = pd.cut(df['Latitude'], bins=np.arange(10, 61, binsize))  # Change bin size to 2 degrees\n",
    "df['Depth_bin'] = pd.cut(df['Depth'], bins=np.arange(0, 700+depthsize, depthsize))\n",
    "\n",
    "# Group the data by longitude bin, latitude bin, depth bin, and day, and compute the maximum magnitude within each group\n",
    "grouped = df.groupby(['Longitude_bin', 'Latitude_bin', 'Depth_bin', pd.Grouper(freq=freq, level=\"Time\")]).max()['Magnitude']\n",
    "grouped = grouped.unstack().fillna(0)\n",
    "\n",
    "# Reshape the resulting data into a tensor_convLSTM with shape (1, time, depth, longitude, latitude)\n",
    "time = len(grouped.columns)\n",
    "depth = len(grouped.index.levels[2])\n",
    "longitude = len(grouped.index.levels[0])\n",
    "latitude = len(grouped.index.levels[1])\n",
    "tensor_convLSTM = np.zeros((1, time, longitude, latitude, depth))\n",
    "\n",
    "for t in range(time):\n",
    "    tensor_convLSTM[0, t, :, :, :] = grouped.iloc[:, t].values.reshape(longitude, latitude, depth)\n",
    "\n",
    "# Rotate dimensions corresponding to 20 and 25, 90 degrees anti-clockwise\n",
    "tensor_convLSTM = np.transpose(tensor_convLSTM, axes=(0, 1, 4, 3, 2))\n",
    "tensor_convLSTM = np.flip(tensor_convLSTM, axis=3)\n",
    "# Print the shape of the resulting tensor_convLSTM\n",
    "print(tensor_convLSTM.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot timesteps of 5D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Choose a timestep to plot (e.g. the first timestep)\n",
    "timestep = 40\n",
    "depth = 5\n",
    "\n",
    "# Extract the data for the chosen timestep from the tensor\n",
    "# tensor_convLSTM = tf.cast(tf.reduce_max(tensor_convLSTM, axis=2, keepdims=True) > 0, dtype=tf.int32)\n",
    "\n",
    "data = tensor_convLSTM[0, timestep, depth, :, :]\n",
    "\n",
    "# Create a heatmap plot of the data using Seaborn\n",
    "sns.set(rc={'figure.figsize':(4.8,6)})\n",
    "sns.heatmap(data, cmap='viridis', vmin=-1, vmax=10, linewidths=0.5, linecolor='grey', annot=False)\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "plt.title(f'Earthquake magnitudes at timestep {timestep}')\n",
    "plt.xlabel('Longitude bin')\n",
    "plt.ylabel('Latitude bin')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data in train en test set\n",
    "dataset_convLSTM = tensor_convLSTM.reshape((tensor_convLSTM.shape[1], tensor_convLSTM.shape[2], tensor_convLSTM.shape[3], tensor_convLSTM.shape[4]))\n",
    "\n",
    "train, val_test = train_test_split(dataset_convLSTM, test_size=.4, shuffle=False, random_state=43)\n",
    "val, test = train_test_split(val_test, test_size=.5, shuffle=False, random_state=43)\n",
    "\n",
    "\"\"\"\n",
    "train = train.reshape((1, train.shape[0], train.shape[1], train.shape[2], train.shape[3]))\n",
    "val = val.reshape((1, val.shape[0], val.shape[1], val.shape[2], val.shape[3]))\n",
    "test = test.reshape((1, test.shape[0], test.shape[1], test.shape[2], test.shape[3]))\n",
    "\n",
    "# We'll define a helper function to shift the frames, where `x` is frames 0 to n - 1, and `y` is frames 1 to n.\n",
    "def create_shifted_frames(data):\n",
    "    x = data[:, 0 : data.shape[1] - 1, :, :]\n",
    "    y = data[:, 1 : data.shape[1], :, :]\n",
    "    return x, y\n",
    "\n",
    "# Apply the processing function to the datasets.\n",
    "x_train, y_train = create_shifted_frames(train)\n",
    "x_val, y_val = create_shifted_frames(val)\n",
    "x_test, y_test = create_shifted_frames(test)\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate datasets from timeseries V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
    "import tensorflow as tf\n",
    "\n",
    "def dataset_generator(data, seq_length, cutoff):\n",
    "\n",
    "  input_data = data # data[:-seq_length]\n",
    "  targets = data[seq_length:]\n",
    "  dataset = timeseries_dataset_from_array(input_data, (targets >= cutoff).astype(int), sequence_length=seq_length, sampling_rate=1, sequence_stride=1, shuffle=False, batch_size=len(data))\n",
    "  \"\"\"\n",
    "  for batch in dataset:\n",
    "    inputs, targets = batch\n",
    "    assert np.array_equal(inputs[0], data[:seq_length])  # First sequence: steps [0-9]\n",
    "    assert np.array_equal(targets[0], data[seq_length])  # Corresponding target: step 10\n",
    "    \"\"\"\n",
    "  return dataset\n",
    "\n",
    "# Set lookback timewindow\n",
    "timewindow = 20\n",
    "\n",
    "train_dataset = dataset_generator(train, timewindow, 4.5)\n",
    "val_dataset = dataset_generator(val, timewindow, 4.5)\n",
    "test_dataset = dataset_generator(test, timewindow, 4.5)\n",
    "\n",
    "# Create train set\n",
    "for batch in train_dataset:\n",
    "    X_train, y_train = batch\n",
    "\n",
    "y_train = tf.reshape(y_train, shape=[y_train.shape[0], 1, y_train.shape[1], y_train.shape[2], y_train.shape[3]])\n",
    "\n",
    "# Collapse the depth dimension and converts all non-zero values to 1 and zero values to 0\n",
    "y_train = tf.cast(tf.reduce_max(y_train, axis=2, keepdims=True) > 0, dtype=tf.int32)\n",
    "\n",
    "# Create validation set\n",
    "for batch in val_dataset:\n",
    "    X_val, y_val = batch\n",
    "\n",
    "y_val = tf.reshape(y_val, shape=[y_val.shape[0], 1, y_val.shape[1], y_val.shape[2], y_val.shape[3]])\n",
    "\n",
    "# Collapse the depth dimension and converts all non-zero values to 1 and zero values to 0\n",
    "y_val = tf.cast(tf.reduce_max(y_val, axis=2, keepdims=True) > 0, dtype=tf.int32)\n",
    "\n",
    "# Create test set\n",
    "for batch in test_dataset:\n",
    "    X_test, y_test = batch\n",
    "\n",
    "y_test = tf.reshape(y_test, shape=[y_test.shape[0], 1, y_test.shape[1], y_test.shape[2], y_test.shape[3]])\n",
    "\n",
    "# Collapse the depth dimension and converts all non-zero values to 1 and zero values to 0\n",
    "y_test = tf.cast(tf.reduce_max(y_test, axis=2, keepdims=True) > 0, dtype=tf.int32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate datasets from timeseries V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
    "import tensorflow as tf\n",
    "\n",
    "def dataset_generator(data, seq_length, cutoff):\n",
    "\n",
    "  input_data = data # data[:-seq_length]\n",
    "  targets = data[seq_length:]\n",
    "  dataset = timeseries_dataset_from_array(input_data, (targets >= cutoff).astype(int), sequence_length=seq_length, sampling_rate=1, sequence_stride=1, shuffle=False, batch_size=len(data))\n",
    "  \"\"\"\n",
    "  for batch in dataset:\n",
    "    inputs, targets = batch\n",
    "    assert np.array_equal(inputs[0], data[:seq_length])  # First sequence: steps [0-9]\n",
    "    assert np.array_equal(targets[0], data[seq_length])  # Corresponding target: step 10\n",
    "    \"\"\"\n",
    "  return dataset\n",
    "\n",
    "timewindow = 10\n",
    "cutoff = 5.5\n",
    "\n",
    "batches = dataset_generator(dataset_convLSTM, timewindow, cutoff)\n",
    "for batch in batches:\n",
    "    X, y = batch\n",
    "    \n",
    "y = tf.reshape(y, shape=[y.shape[0], 1, y.shape[1], y.shape[2], y.shape[3]])\n",
    "y = tf.cast(tf.reduce_max(y, axis=2, keepdims=True) > 0, dtype=tf.int32)\n",
    "\n",
    "X_train, X_val_test = train_test_split(np.array(X), test_size=.4, shuffle=True, random_state=43)\n",
    "X_val, X_test = train_test_split(X_val_test, test_size=.5, shuffle=True, random_state=43)\n",
    "\n",
    "y_train, y_val_test = train_test_split(np.array(y), test_size=.4, shuffle=True, random_state=43)\n",
    "y_val, y_test = train_test_split(y_val_test, test_size=.5, shuffle=True, random_state=43)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelconstruction of convLSTM2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, regularizers\n",
    "import keras\n",
    "keras.backend.clear_session()\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Construct the inputut layer with no definite frame size.\n",
    "input = layers.Input(shape=(X_train.shape[1:]))\n",
    "\n",
    "# We will construct 3 `ConvLSTM2D` layers with batch normalization,\n",
    "# followed by a `Conv3D` layer for the spatiotemporal outputs.\n",
    "x = layers.BatchNormalization()(input)\n",
    "x = layers.ConvLSTM2D(\n",
    "    filters=164,\n",
    "    kernel_size=(3, 3),\n",
    "    padding=\"same\",\n",
    "    return_sequences=True,\n",
    "    activation=\"relu\",\n",
    "    data_format = \"channels_first\",\n",
    "    # kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4)\n",
    ")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ConvLSTM2D(\n",
    "    filters=1,\n",
    "    kernel_size=(1, 1),\n",
    "    padding=\"same\",\n",
    "    return_sequences=False,\n",
    "    activation=\"relu\",\n",
    "    data_format = \"channels_first\",\n",
    "    kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4)\n",
    ")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.reshape(x, (-1, 1, x.shape[1], x.shape[2], x.shape[3]))\n",
    "x = layers.Conv3D(filters=x.shape[4], kernel_size=(3, 3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n",
    "# Next, we will build the complete model and compile it.\n",
    "model = keras.models.Model(input, x)\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=[keras.metrics.Precision(), keras.metrics.Recall(), 'accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeltraining of convLSTM2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some callbacks to improve training.\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define modifiable training hyperparameters.\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "# Fit the model to the training data.\n",
    "model.fit(x=X_train,\n",
    "          y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Choose timesteps to plot\n",
    "timestep = 10\n",
    "\n",
    "# Extract the data for the chosen timesteps from the tensor\n",
    "data1 = y_pred[timestep, 0, 0, :, :] > .5\n",
    "data2 = y_test[timestep, 0, 0, :, :]\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 6))\n",
    "\n",
    "# Plot the data in each subplot\n",
    "sns.heatmap(data1, cmap='viridis', vmin=-1, vmax=10, linewidths=0.5, linecolor='grey', annot=False, ax=ax1)\n",
    "sns.heatmap(data2, cmap='viridis', vmin=-1, vmax=10, linewidths=0.5, linecolor='grey', annot=False, ax=ax2)\n",
    "\n",
    "# Set the plot titles and axis labels\n",
    "ax1.set_title(f'Earthquake magnitudes at timestep {timestep}')\n",
    "ax1.set_xlabel('Longitude bin')\n",
    "ax1.set_ylabel('Latitude bin')\n",
    "\n",
    "ax2.set_title(f'Earthquake magnitudes at timestep {timestep}')\n",
    "ax2.set_xlabel('Longitude bin')\n",
    "ax2.set_ylabel('Latitude bin')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "p = sns.heatmap(confusion_matrix(np.array(y_test).flatten(), y_pred.flatten() >= 0.5), annot=True, fmt='g')\n",
    "p.set_xlabel(\"Predicted\")\n",
    "p.set_ylabel(\"True\")\n",
    "p.xaxis.set_ticklabels(['M<6', 'M>=6'], ha=\"center\", va=\"center\")\n",
    "p.yaxis.set_ticklabels(['M<6', 'M>=6'], rotation=0, va=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(np.array(y_test).flatten(), y_pred.flatten() >= 0.5)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(np.array(y_test).flatten(), y_pred.flatten() >= 0.5)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(np.array(y_test).flatten(), y_pred.flatten() >= 0.5)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(np.array(y_test).flatten(), y_pred.flatten() >= 0.5)\n",
    "print('F1 score: %f' % f1)\n",
    "\n",
    "class_names = ['M<6', 'M>=6']\n",
    "\n",
    "print(classification_report(np.array(y_test).flatten(), y_pred.flatten() >= 0.5, target_names=class_names))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvLSTM3d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 6D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 600, 1, 10, 8, 5)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Choose frequency and binsize\n",
    "freq = 'M'  # Change frequency to days\n",
    "binsize = 5\n",
    "depthsize = 140\n",
    "# Load earthquake data into a pandas DataFrame\n",
    "df = pd.read_csv('data/Japan_10_60_134_174_1973_2023_V2.csv')\n",
    "df['Time'] = pd.to_datetime(df.Time)\n",
    "df = df.set_index('Time')\n",
    "df = df.sort_index()\n",
    "\n",
    "# Bin the longitude and latitude values into 2x2 degree bins\n",
    "df['Longitude_bin'] = pd.cut(df['Longitude'], bins=np.arange(134, 175, binsize))  # Change bin size to 2 degrees\n",
    "df['Latitude_bin'] = pd.cut(df['Latitude'], bins=np.arange(10, 61, binsize))  # Change bin size to 2 degrees\n",
    "df['Depth_bin'] = pd.cut(df['Depth'], bins=np.arange(0, 700+depthsize, depthsize))\n",
    "\n",
    "# Group the data by longitude bin, latitude bin, depth bin, and day, and compute the maximum magnitude within each group\n",
    "grouped = df.groupby(['Longitude_bin', 'Latitude_bin', 'Depth_bin', pd.Grouper(freq=freq, level=\"Time\")]).max()['Magnitude']\n",
    "grouped = grouped.unstack().fillna(0)\n",
    "\n",
    "# Reshape the resulting data into a tensor6D_convLSTM3D with shape (1, time, depth, longitude, latitude)\n",
    "time = len(grouped.columns)\n",
    "depth = len(grouped.index.levels[2])\n",
    "longitude = len(grouped.index.levels[0])\n",
    "latitude = len(grouped.index.levels[1])\n",
    "channels = 1\n",
    "tensor6D_convLSTM3D = np.zeros((1, time, channels, longitude, latitude, depth))\n",
    "\n",
    "for t in range(time):\n",
    "    tensor6D_convLSTM3D[0, t, 0, :, :, :] = grouped.iloc[:, t].values.reshape(longitude, latitude, depth)\n",
    "\n",
    "# Rotate dimensions corresponding to 20 and 25, 90 degrees anti-clockwise\n",
    "tensor6D_convLSTM3D = np.transpose(tensor6D_convLSTM3D, axes=(0, 1, 2, 4, 3, 5))\n",
    "tensor6D_convLSTM3D = np.flip(tensor6D_convLSTM3D, axis=3)\n",
    "# Print the shape of the resulting tensor6D_convLSTM3D\n",
    "print(tensor6D_convLSTM3D.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot timesteps of 6D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Choose a timestep to plot (e.g. the first timestep)\n",
    "timestep = 10\n",
    "depth = 0\n",
    "channel = 0\n",
    "\n",
    "# Extract the data for the chosen timestep from the tensor\n",
    "# tensor_convLSTM = tf.cast(tf.reduce_max(tensor_convLSTM, axis=2, keepdims=True) > 0, dtype=tf.int32)\n",
    "\n",
    "data = tensor6D_convLSTM3D[0, timestep, channel, :, :, depth]\n",
    "\n",
    "# Create a heatmap plot of the data using Seaborn\n",
    "sns.set(rc={'figure.figsize':(4.8,6)})\n",
    "sns.heatmap(data, cmap='viridis', vmin=-1, vmax=10, linewidths=0.5, linecolor='grey', annot=False)\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "plt.title(f'Earthquake magnitudes at timestep {timestep}')\n",
    "plt.xlabel('Longitude bin')\n",
    "plt.ylabel('Latitude bin')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain = train.reshape((1, train.shape[0], train.shape[1], train.shape[2], train.shape[3]))\\nval = val.reshape((1, val.shape[0], val.shape[1], val.shape[2], val.shape[3]))\\ntest = test.reshape((1, test.shape[0], test.shape[1], test.shape[2], test.shape[3]))\\n\\n# We'll define a helper function to shift the frames, where `x` is frames 0 to n - 1, and `y` is frames 1 to n.\\ndef create_shifted_frames(data):\\n    x = data[:, 0 : data.shape[1] - 1, :, :]\\n    y = data[:, 1 : data.shape[1], :, :]\\n    return x, y\\n\\n# Apply the processing function to the datasets.\\nx_train, y_train = create_shifted_frames(train)\\nx_val, y_val = create_shifted_frames(val)\\nx_test, y_test = create_shifted_frames(test)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data in train en test set\n",
    "tensor6D_convLSTM3D = tensor6D_convLSTM3D.reshape((tensor6D_convLSTM3D.shape[1], tensor6D_convLSTM3D.shape[2], tensor6D_convLSTM3D.shape[3], tensor6D_convLSTM3D.shape[4], tensor6D_convLSTM3D.shape[5]))\n",
    "\n",
    "train, val_test = train_test_split(tensor6D_convLSTM3D, test_size=.4, shuffle=False, random_state=43)\n",
    "val, test = train_test_split(val_test, test_size=.5, shuffle=False, random_state=43)\n",
    "\n",
    "\"\"\"\n",
    "train = train.reshape((1, train.shape[0], train.shape[1], train.shape[2], train.shape[3]))\n",
    "val = val.reshape((1, val.shape[0], val.shape[1], val.shape[2], val.shape[3]))\n",
    "test = test.reshape((1, test.shape[0], test.shape[1], test.shape[2], test.shape[3]))\n",
    "\n",
    "# We'll define a helper function to shift the frames, where `x` is frames 0 to n - 1, and `y` is frames 1 to n.\n",
    "def create_shifted_frames(data):\n",
    "    x = data[:, 0 : data.shape[1] - 1, :, :]\n",
    "    y = data[:, 1 : data.shape[1], :, :]\n",
    "    return x, y\n",
    "\n",
    "# Apply the processing function to the datasets.\n",
    "x_train, y_train = create_shifted_frames(train)\n",
    "x_val, y_val = create_shifted_frames(val)\n",
    "x_test, y_test = create_shifted_frames(test)\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate dataset from timeseries V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-19 21:33:09.818340: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
    "import tensorflow as tf\n",
    "\n",
    "def dataset_generator(data, seq_length, cutoff):\n",
    "\n",
    "  input_data = data # data[:-seq_length]\n",
    "  targets = data[seq_length:]\n",
    "  dataset = timeseries_dataset_from_array(input_data, (targets >= cutoff).astype(int), sequence_length=seq_length, sampling_rate=1, sequence_stride=1, shuffle=False, batch_size=len(data))\n",
    "  \"\"\"\n",
    "  for batch in dataset:\n",
    "    inputs, targets = batch\n",
    "    assert np.array_equal(inputs[0], data[:seq_length])  # First sequence: steps [0-9]\n",
    "    assert np.array_equal(targets[0], data[seq_length])  # Corresponding target: step 10\n",
    "    \"\"\"\n",
    "  return dataset\n",
    "\n",
    "# Set lookback timewindow\n",
    "timewindow = 10\n",
    "\n",
    "train_dataset = dataset_generator(train, timewindow, 4.5)\n",
    "val_dataset = dataset_generator(val, timewindow, 4.5)\n",
    "test_dataset = dataset_generator(test, timewindow, 4.5)\n",
    "\n",
    "# Create train set\n",
    "for batch in train_dataset:\n",
    "    X_train, y_train = batch\n",
    "\n",
    "y_train = tf.reshape(y_train, shape=[y_train.shape[0], 1, 1, y_train.shape[2], y_train.shape[3], y_train.shape[4]])\n",
    "\n",
    "# Collapse the depth dimension and converts all non-zero values to 1 and zero values to 0\n",
    "y_train = tf.cast(tf.reduce_max(y_train, axis=5, keepdims=True) > 0, dtype=tf.int32)\n",
    "\n",
    "# Create validation set\n",
    "for batch in val_dataset:\n",
    "    X_val, y_val = batch\n",
    "\n",
    "y_val = tf.reshape(y_val, shape=[y_val.shape[0], 1, 1, y_val.shape[2], y_val.shape[3], y_val.shape[4]])\n",
    "\n",
    "# Collapse the depth dimension and converts all non-zero values to 1 and zero values to 0\n",
    "y_val = tf.cast(tf.reduce_max(y_val, axis=5, keepdims=True) > 0, dtype=tf.int32)\n",
    "\n",
    "# Create test set\n",
    "for batch in test_dataset:\n",
    "    X_test, y_test = batch\n",
    "\n",
    "y_test = tf.reshape(y_test, shape=[y_test.shape[0], 1, 1, y_test.shape[2], y_test.shape[3], y_test.shape[4]])\n",
    "\n",
    "# Collapse the depth dimension and converts all non-zero values to 1 and zero values to 0\n",
    "y_test = tf.cast(tf.reduce_max(y_test, axis=5, keepdims=True) > 0, dtype=tf.int32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelconstruction of ConvLSTM3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10, 1, 10, 8, 5)  0         \n",
      "                             ]                                   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 10, 1, 10, 8, 5)  20        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv_lstm3d (ConvLSTM3D)    (None, 10, 8, 10, 8, 5)   18464     \n",
      "                                                                 \n",
      " conv_lstm3d_1 (ConvLSTM3D)  (None, 10, 8, 10, 8, 5)   32800     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 10, 8, 10, 8, 5)  20        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv_lstm3d_2 (ConvLSTM3D)  (None, 1, 10, 8, 5)       40        \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 1, 10, 8, 5)      20        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " tf.reshape (TFOpLambda)     (None, 1, 1, 10, 8, 5)    0         \n",
      "                                                                 \n",
      " conv3d (Conv3D)             (None, 1, 1, 10, 8, 1)    626       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51,990\n",
      "Trainable params: 51,960\n",
      "Non-trainable params: 30\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, regularizers\n",
    "import keras\n",
    "keras.backend.clear_session()\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Construct the inputut layer with no definite frame size.\n",
    "input = layers.Input(shape=(X_train.shape[1:]))\n",
    "\n",
    "# We will construct 3 `ConvLSTM2D` layers with batch normalization,\n",
    "# followed by a `Conv3D` layer for the spatiotemporal outputs.\n",
    "x = layers.BatchNormalization()(input)\n",
    "x = layers.ConvLSTM3D(\n",
    "    filters=8,\n",
    "    kernel_size=(4, 4, 4),\n",
    "    padding=\"same\",\n",
    "    return_sequences=True,\n",
    "    activation=\"relu\",\n",
    "    data_format = \"channels_first\",\n",
    "    # kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4)\n",
    ")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ConvLSTM3D(\n",
    "    filters=1,\n",
    "    kernel_size=(1, 1, 1),\n",
    "    padding=\"same\",\n",
    "    return_sequences=False,\n",
    "    activation=\"relu\",\n",
    "    data_format = \"channels_first\",\n",
    "    kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4)\n",
    ")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.reshape(x, (-1, 1, 1, x.shape[2], x.shape[3], x.shape[4]))\n",
    "x = layers.Conv3D(filters=1, kernel_size=(5, 5, 5), activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "# Next, we will build the complete model and compile it.\n",
    "model = keras.models.Model(input, x)\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=[keras.metrics.Precision(), keras.metrics.Recall(), 'accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeltraining of ConvLSTM3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 11s 709ms/step - loss: 0.6253 - precision: 0.3841 - recall: 0.6490 - accuracy: 0.7323 - val_loss: 0.6818 - val_precision: 0.4876 - val_recall: 0.8293 - val_accuracy: 0.7835 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 8s 697ms/step - loss: 0.4914 - precision: 0.6072 - recall: 0.8411 - accuracy: 0.8648 - val_loss: 0.6543 - val_precision: 0.7230 - val_recall: 0.1100 - val_accuracy: 0.8064 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 8s 704ms/step - loss: 0.4167 - precision: 0.6448 - recall: 0.8710 - accuracy: 0.8829 - val_loss: 0.6189 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_accuracy: 0.7923 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 8s 698ms/step - loss: 0.3671 - precision: 0.6935 - recall: 0.8389 - accuracy: 0.8977 - val_loss: 0.5892 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_accuracy: 0.7923 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 8s 706ms/step - loss: 0.3246 - precision: 0.7330 - recall: 0.8320 - accuracy: 0.9094 - val_loss: 0.5645 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_accuracy: 0.7923 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 8s 702ms/step - loss: 0.2907 - precision: 0.7510 - recall: 0.8359 - accuracy: 0.9151 - val_loss: 0.5400 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_accuracy: 0.7923 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 8s 706ms/step - loss: 0.2649 - precision: 0.7668 - recall: 0.8192 - accuracy: 0.9173 - val_loss: 0.5230 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_accuracy: 0.7923 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 8s 710ms/step - loss: 0.2458 - precision: 0.7712 - recall: 0.8160 - accuracy: 0.9180 - val_loss: 0.5121 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_accuracy: 0.7923 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 8s 698ms/step - loss: 0.2321 - precision: 0.7818 - recall: 0.8053 - accuracy: 0.9193 - val_loss: 0.5100 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_accuracy: 0.7923 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 8s 719ms/step - loss: 0.2217 - precision: 0.7851 - recall: 0.7930 - accuracy: 0.9184 - val_loss: 0.5151 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_accuracy: 0.7923 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 8s 704ms/step - loss: 0.2144 - precision: 0.7833 - recall: 0.8006 - accuracy: 0.9190 - val_loss: 0.5249 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_accuracy: 0.7923 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 8s 719ms/step - loss: 0.2101 - precision: 0.7876 - recall: 0.7923 - accuracy: 0.9189 - val_loss: 0.5480 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_accuracy: 0.7923 - lr: 0.0010\n",
      "Epoch 13/100\n",
      " 5/11 [============>.................] - ETA: 3s - loss: 0.2058 - precision: 0.7899 - recall: 0.7915 - accuracy: 0.9202"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[39m# Fit the model to the training data.\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mX_train,\n\u001b[1;32m     11\u001b[0m           y\u001b[39m=\u001b[39;49my_train,\n\u001b[1;32m     12\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m     13\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m     14\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(X_val, y_val),\n\u001b[1;32m     15\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[early_stopping, reduce_lr],\n\u001b[1;32m     16\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tflow/lib/python3.9/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tflow/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tflow/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tflow/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tflow/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tflow/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tflow/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tflow/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define some callbacks to improve training.\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "# Define modifiable training hyperparameters.\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "# Fit the model to the training data.\n",
    "model.fit(x=X_train,\n",
    "          y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 140ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'M<6'), Text(0, 1.5, 'M>=6')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "p = sns.heatmap(confusion_matrix(np.array(y_test).flatten(), y_pred.flatten() >= 0.5), annot=True, fmt='g')\n",
    "p.set_xlabel(\"Predicted\")\n",
    "p.set_ylabel(\"True\")\n",
    "p.xaxis.set_ticklabels(['M<6', 'M>=6'], ha=\"center\", va=\"center\")\n",
    "p.yaxis.set_ticklabels(['M<6', 'M>=6'], rotation=0, va=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.904205\n",
      "Precision: 0.795896\n",
      "Recall: 0.751309\n",
      "F1 score: 0.772960\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         M<6       0.93      0.95      0.94      6890\n",
      "        M>=6       0.80      0.75      0.77      1910\n",
      "\n",
      "    accuracy                           0.90      8800\n",
      "   macro avg       0.86      0.85      0.86      8800\n",
      "weighted avg       0.90      0.90      0.90      8800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(np.array(y_test).flatten(), y_pred.flatten() >= 0.5)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(np.array(y_test).flatten(), y_pred.flatten() >= 0.5)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(np.array(y_test).flatten(), y_pred.flatten() >= 0.5)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(np.array(y_test).flatten(), y_pred.flatten() >= 0.5)\n",
    "print('F1 score: %f' % f1)\n",
    "\n",
    "class_names = ['M<6', 'M>=6']\n",
    "\n",
    "print(classification_report(np.array(y_test).flatten(), y_pred.flatten() >= 0.5, target_names=class_names))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hereafter is mainly redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emdat = pd.read_excel(\"/Users/jurrienboogert/Downloads/emdat_public_2023_02_08_query_uid-jHccdA.xlsx\", header=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emdat[emdat['Disaster Type'] == 'Earthquake'][['Dis Mag Value']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_file='/Users/jurrienboogert/Documents/DATA_SCIENCE_AND_SOCIETY/THESIS/datasets/NOAA/earthquakes-2023-02-11_10-24-26_+0100.tsv'\n",
    "NOAA=pd.read_table(tsv_file,sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOAA[(NOAA['Total Deaths'] > 0) | (NOAA['Total Damage ($Mil)'] > 0)]['Mag']\n",
    "\n",
    "plt.hist(NOAA[(NOAA['Total Deaths'] > 0) | (NOAA['Total Damage ($Mil)'] > 0)]['Mag'], bins=80)\n",
    "plt.show()\n",
    "\n",
    "NOAA[(NOAA['Total Deaths'] > 0) | (NOAA['Total Damage ($Mil)'] > 0)]['Mag'].quantile(.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOAA.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(NOAA[NOAA['Year'] > 2010][['year', 'month', 'day', 'hour', 'minute']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk1 = pd.read_csv(\"/Users/jurrienboogert/Documents/DATA_SCIENCE_AND_SOCIETY/THESIS/datasets/STEAD/chunk1.csv\", low_memory=False)\n",
    "chunk2 = pd.read_csv(\"/Users/jurrienboogert/Documents/DATA_SCIENCE_AND_SOCIETY/THESIS/datasets/STEAD/chunk2.csv\", low_memory=False)\n",
    "chunk3 = pd.read_csv(\"/Users/jurrienboogert/Documents/DATA_SCIENCE_AND_SOCIETY/THESIS/datasets/STEAD/chunk3.csv\", low_memory=False)\n",
    "chunk4 = pd.read_csv(\"/Users/jurrienboogert/Documents/DATA_SCIENCE_AND_SOCIETY/THESIS/datasets/STEAD/chunk4.csv\", low_memory=False)\n",
    "chunk5 = pd.read_csv(\"/Users/jurrienboogert/Documents/DATA_SCIENCE_AND_SOCIETY/THESIS/datasets/STEAD/chunk5.csv\", low_memory=False)\n",
    "chunk6 = pd.read_csv(\"/Users/jurrienboogert/Documents/DATA_SCIENCE_AND_SOCIETY/THESIS/datasets/STEAD/chunk6.csv\", low_memory=False)\n",
    "\n",
    "chunks = pd.concat([chunk2,chunk3,chunk4,chunk5,chunk6], ignore_index=True)\n",
    "chunks['trace_start_time'] = pd.to_datetime(chunks['trace_start_time'])\n",
    "chunks['source_origin_time'] = pd.to_datetime(chunks['source_origin_time'])\n",
    "chunks = chunks.sort_values('source_origin_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "subset = chunks[(chunks['source_longitude'] >= 19) & (chunks['source_longitude'] <= 30) & (chunks['source_latitude'] >= 34) & (chunks['source_latitude'] <= 44) & (chunks['source_origin_time'] <= '2015-6-25 03:14:47.900')]\n",
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "plt.scatter(subset.source_origin_time, subset.source_magnitude, s=1)\n",
    "plt.ylabel('Magnitude')\n",
    "plt.xlabel('Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(subset.source_magnitude, bins=48)\n",
    "plt.xlabel('magnitude')\n",
    "plt.ylabel('Number of Earthquakes')\n",
    "plt.title('Histogram of Earthquakes by magnitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create a histogram of the longitude values\n",
    "plt.hist(subset.source_latitude, bins=360)\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Number of Earthquakes')\n",
    "plt.title('Histogram of Earthquakes by Longitude')\n",
    "plt.show()\n",
    "\n",
    "# create a histogram of the latitude values\n",
    "plt.hist(subset.source_longitude, bins=360)\n",
    "plt.xlabel('Latitude')\n",
    "plt.ylabel('Number of Earthquakes')\n",
    "plt.title('Histogram of Earthquakes by Latitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import numpy as np\n",
    "\n",
    "# Load earthquake data\n",
    "df = subset[chunks['source_magnitude'] >= 0].sort_values('source_magnitude')\n",
    "\n",
    "# Extract latitude and longitude columns\n",
    "latitudes = df['source_latitude']\n",
    "longitudes = df['source_longitude']\n",
    "magnitudes = df['source_magnitude']\n",
    "\n",
    "# Set up map projection\n",
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "map = Basemap(projection='merc', lat_0=0, lon_0=0, resolution='l',\n",
    "              llcrnrlon=19, llcrnrlat=33, urcrnrlon=30, urcrnrlat=43)\n",
    "\n",
    "# Draw coastlines, countries, and states\n",
    "#map.drawcoastlines(color='gray')\n",
    "map.fillcontinents(color='lightgray', lake_color='white')\n",
    "map.drawmapboundary(fill_color='white')\n",
    "\n",
    "# Draw parallels and meridians\n",
    "map.drawparallels(range(-90, 90, 1), linewidth=0.5, labels=[1, 0, 0, 0])\n",
    "meridians = map.drawmeridians(range(-180, 180, 1), linewidth=0.5, labels=[0, 0, 0, 1])\n",
    "\n",
    "for m in meridians:\n",
    "    try:\n",
    "        meridians[m][1][0].set_rotation(45)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Convert latitude and longitude to map coordinates\n",
    "x, y = map(longitudes, latitudes)\n",
    "\n",
    "# Plot earthquake magnitudes as circles on the map\n",
    "map.scatter(x, y, s=np.exp(magnitudes)/50, c=magnitudes, cmap='plasma', alpha=1)\n",
    "\n",
    "# Add a colorbar\n",
    "plt.colorbar(label='Magnitude')\n",
    "\n",
    "# Add a title\n",
    "plt.title('Earthquake Magnitudes')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "\n",
    "# group the data by date and location to create the input data for Prophet\n",
    "data = chunks.groupby([pd.Grouper(key='source_origin_time', freq='D'), 'source_latitude', 'source_longitude']).size().reset_index(name='count')\n",
    "\n",
    "# rename columns for use with Prophet\n",
    "data = data.rename(columns={'source_origin_time': 'ds', 'count': 'y'})\n",
    "\n",
    "# create a Prophet model and fit the data\n",
    "model = Prophet()\n",
    "model.fit(data)\n",
    "\n",
    "# create a future dataframe with predictions for the next 365 days\n",
    "future = model.make_future_dataframe(periods=7)\n",
    "\n",
    "# predict the number of earthquakes for the future dates\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# plot the forecast\n",
    "fig = model.plot(forecast, xlabel='Date', ylabel='Number of Earthquakes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(chunks['source_origin_time'], chunks['source_magnitude'], 'ro', alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks[['source_magnitude', 'trace_start_time', 'source_origin_time', 'receiver_latitude', 'receiver_longitude', 'source_latitude', 'source_longitude']].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks[(chunks['source_origin_time'].dt.year == 2007) & (chunks['source_origin_time'].dt.month == 8) & (chunks['source_origin_time'].dt.day == 17) & (chunks['source_origin_time'].dt.hour == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks[chunks['source_magnitude'] > 6].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOAA[(NOAA['Year'] > 1983) & (NOAA['Deaths'] > 0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv(\"/Users/jurrienboogert/Downloads/2023.csv\", header=None, names=['ID', 'YEAR/MONTH/DAY', 'ELEMENT', 'DATA VALUE', 'M-FLAG', 'Q-FLAG', 'S-FLAG', 'OBS-TIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dly = pd.read_fwf('/Users/jurrienboogert/Downloads/ghcnd_gsn/ghcnd_gsn/USW00013782.dly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = chunks.sample(1)[['source_latitude', 'source_longitude']]\n",
    "source.iloc[0,0], source.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Meteostat library and dependencies\n",
    "from datetime import datetime\n",
    "from meteostat import Point, Hourly\n",
    "\n",
    "# Set time period\n",
    "start = datetime(1984, 9, 7, 2)\n",
    "end = datetime(1984, 9, 7, 3)\n",
    "\n",
    "# Create Point for Vancouver, BC\n",
    "Point.method = 'nearest'\n",
    "Point.radius = 200000\n",
    "Point.max_count = 6\n",
    "Point.weight_dist = .6\n",
    "receiver = Point(source.iloc[0,0], source.iloc[0,1])\n",
    "# Get daily data for 2018\n",
    "data = Hourly(receiver, start, end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks['source_origin_time'] = pd.to_datetime(chunks['source_origin_time'])\n",
    "year = chunks['source_origin_time'].dt.year.fillna(0).astype('int')\n",
    "month = chunks['source_origin_time'].dt.month.fillna(0).astype('int')\n",
    "day = chunks['source_origin_time'].dt.day.fillna(0).astype('int')\n",
    "hour = chunks['source_origin_time'].dt.hour.fillna(0).astype('int')\n",
    "\n",
    "chunks.source_latitude\n",
    "chunks.source_longitude\n",
    "\n",
    "chunks.receiver_latitude\n",
    "chunks.receiver_longitude\n",
    "chunks.receiver_elevation_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Meteostat library and dependencies\n",
    "from datetime import datetime\n",
    "from meteostat import Point, Hourly\n",
    "\n",
    "temp_source = []\n",
    "rhum_source = []\n",
    "pres_source = []\n",
    "temp_receiver = []\n",
    "rhum_receiver = []\n",
    "pres_receiver = []\n",
    "counter = 0\n",
    "\n",
    "Point.method = 'nearest'\n",
    "Point.radius = 2000000\n",
    "Point.max_count = 10\n",
    "Point.weight_dist = .6\n",
    "\n",
    "for i in range(235426,len(chunks)):\n",
    "    counter += 1\n",
    "    start = datetime(year[i], month[i], day[i], hour[i])\n",
    "    end = start\n",
    "\n",
    "    source = Point(chunks.source_latitude[i], chunks.source_longitude[i])\n",
    "    # Get daily data for 2018\n",
    "    temp_source.append(Hourly(source, start, end).fetch()['temp'][0])\n",
    "    rhum_source.append(Hourly(source, start, end).fetch()['rhum'][0])\n",
    "    pres_source.append(Hourly(source, start, end).fetch()['pres'][0])\n",
    "\n",
    "    if counter % 10 == 0:\n",
    "        print(counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Meteostat library and dependencies\n",
    "from datetime import datetime\n",
    "from meteostat import Point, Daily\n",
    "\n",
    "temp_source = []\n",
    "pres_source = []\n",
    "temp_receiver = []\n",
    "pres_receiver = []\n",
    "counter = 0\n",
    "\n",
    "Point.method = 'nearest'\n",
    "Point.radius = 2000000\n",
    "Point.max_count = 10\n",
    "Point.weight_dist = .6\n",
    "\n",
    "for i in range(235426,len(chunks)):\n",
    "    counter += 1\n",
    "    start = datetime(year[i], month[i], day[i])\n",
    "    end = start\n",
    "\n",
    "    source = Point(chunks.source_latitude[i], chunks.source_longitude[i])\n",
    "    # Get daily data for 2018\n",
    "    temp_source.append(Daily(source, start, end).fetch()['tavg'][0])\n",
    "    pres_source.append(Daily(source, start, end).fetch()['pres'][0])\n",
    "\n",
    "    Point.alt_range = chunks.receiver_elevation_m[i]\n",
    "    Point.adapt_temp = True\n",
    "    receiver = Point(chunks.receiver_latitude[i], chunks.receiver_longitude[i], chunks.receiver_elevation_m[i])\n",
    "    # Get daily data for 2018\n",
    "    temp_receiver.append(Daily(receiver, start, end).fetch()['tavg'][0])\n",
    "    pres_receiver.append(Daily(receiver, start, end).fetch()['pres'][0])\n",
    "    if counter % 10 == 0:\n",
    "        print(counter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8acd2a4c40bb06440d03e583eeea35c6596324a3385dafe16353bbc1939be192"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
