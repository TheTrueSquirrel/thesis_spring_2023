{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2609, 10, 8, 4)\n",
      "(2609, 80)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Choose frequency, binsize, longitude, latitude\n",
    "freq = 'W'\n",
    "binsize = 5\n",
    "longitude_W = 134  # minimum is 134\n",
    "longitude_E = 174  # maximum is 174\n",
    "latitude_S = 10  # minimum is 10\n",
    "latitude_N = 60  # minimum is 60\n",
    "\n",
    "# load earthquake data for defined area\n",
    "data = pd.read_csv('data/Japan_10_60_134_174_1973_2023_V2.csv', index_col=0)\n",
    "data['Time'] = pd.to_datetime(data.Time)\n",
    "data = data[(data.Longitude >= longitude_W) & (data.Longitude <= longitude_E) & (data.Latitude >= latitude_S) & (data.Latitude <= latitude_N)]\n",
    "data.set_index('Time', inplace=True)\n",
    "df = data.sort_index()\n",
    "\n",
    "# Bin the longitude and latitude values into 2x2 degree bins\n",
    "df['Longitude_bin'] = pd.cut(df['Longitude'], bins=np.arange(longitude_W, longitude_E + 1, binsize))  # Change bin size to 2 degrees\n",
    "df['Latitude_bin'] = pd.cut(df['Latitude'], bins=np.arange(latitude_S, latitude_N + 1, binsize))  # Change bin size to 2 degrees\n",
    "\n",
    "# Group the data by longitude bin, latitude bin, depth bin, and day, and compute the maximum magnitude within each group\n",
    "grouped = df.groupby(['Longitude_bin', 'Latitude_bin', pd.Grouper(freq=freq, level=\"Time\")]).agg({'Magnitude': 'max', 'Depth': 'mean'})\n",
    "grouped = grouped.unstack().fillna(0)\n",
    "\n",
    "# Reshape the resulting data into a tensor with shape (time, longitude, latitude, 4)\n",
    "time = len(grouped.columns.levels[1])\n",
    "longitude = len(grouped.index.levels[0])\n",
    "latitude = len(grouped.index.levels[1])\n",
    "tensor = np.zeros((time, longitude, latitude, 4))\n",
    "\n",
    "for t in range(time):\n",
    "    tensor[t, :, :, 0] = grouped['Magnitude'].iloc[:, t].values.reshape(longitude, latitude)\n",
    "    tensor[t, :, :, 3] = grouped['Depth'].iloc[:, t].values.reshape(longitude, latitude)\n",
    "\n",
    "latitude_values = np.linspace(latitude_S, latitude_N - binsize, latitude) + binsize / 2\n",
    "longitude_values = np.linspace(longitude_W, longitude_E - binsize, longitude) + binsize / 2\n",
    "\n",
    "tensor[:, :, :, 1] = np.repeat(latitude_values, longitude).reshape(latitude, longitude).T\n",
    "tensor[:, :, :, 2] = np.tile(longitude_values, latitude).reshape(latitude, longitude).T\n",
    "\n",
    "# Rotate dimensions corresponding to 20 and 25, 90 degrees anti-clockwise\n",
    "tensor = np.transpose(tensor, axes=(0, 2, 1, 3))\n",
    "tensor = np.flip(tensor, axis=1)\n",
    "\n",
    "# Print the shape of the tensor\n",
    "print(tensor.shape)\n",
    "\n",
    "# Reshape tensor into matrix\n",
    "matrix = np.reshape(tensor[:,:,:,0], (tensor.shape[0], -1))\n",
    "# Keep only the columns with at least one number bigger than 0\n",
    "matrix = matrix[:, (matrix > 0).sum(axis=0) >= 0]\n",
    "print(matrix.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data in train, val, test\n",
    "\n",
    "# Activate when only forecasting one region\n",
    "# matrix = np.reshape(matrix, (matrix.shape[0], matrix.shape[1], 1))\n",
    "\n",
    "train, val_test = train_test_split(matrix, test_size=.3, shuffle=False, random_state=43)\n",
    "val, test = train_test_split(val_test, test_size=.5, shuffle=False, random_state=43)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create sliding window datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(365, 29120) (365, 80)\n",
      "(6, 29120) (6, 80)\n",
      "(7, 29120) (7, 80)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
    "import tensorflow as tf\n",
    "\n",
    "def dataset_generator(data, seq_length, samp_rate, stride, cutoff):\n",
    "\n",
    "  input_data = data\n",
    "  target_data = data\n",
    "  dataset = timeseries_dataset_from_array(input_data, targets=None, sequence_length=seq_length, sampling_rate=samp_rate, sequence_stride=stride, shuffle=False, batch_size=len(data))\n",
    "\n",
    "  return dataset\n",
    "\n",
    "# Set lookback timewindow\n",
    "lookback_window = 52 * 6\n",
    "cutoff = 4.5\n",
    "future_timesteps = 4\n",
    "timewindow = lookback_window + future_timesteps\n",
    "samp_rate = 1\n",
    "stride = future_timesteps\n",
    "\n",
    "train_dataset = dataset_generator(train, timewindow, samp_rate, stride, cutoff)\n",
    "val_dataset = dataset_generator(val, timewindow, samp_rate, stride, cutoff)\n",
    "test_dataset = dataset_generator(test, timewindow, samp_rate, stride, cutoff)\n",
    "\n",
    "# Create train set\n",
    "for batch in train_dataset:\n",
    "    X_train = batch[:,:-future_timesteps,:]\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "\n",
    "    y_train = batch[:,-future_timesteps:,:] >= cutoff\n",
    "    y_train = np.max(y_train, axis=1).astype(int)\n",
    "    # y_train = np.reshape(y_train, (y_train.shape[0], 1, y_train.shape[1])).astype(int)\n",
    "\n",
    "# y_train = tf.reshape(y_train, shape=[y_train.shape[0], 1, y_train.shape[1]])\n",
    "\n",
    "# Collapse the depth dimension and converts all non-zero values to 1 and zero values to 0\n",
    "# y_train = tf.cast(tf.reduce_max(y_train, axis=2, keepdims=True) > 0, dtype=tf.int32)\n",
    "\n",
    "# Create validation set\n",
    "for batch in val_dataset:\n",
    "    X_val = batch[:,:-future_timesteps,:]\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "\n",
    "    y_val = batch[:,-future_timesteps:,:] >= cutoff\n",
    "    y_val = np.max(y_val, axis=1).astype(int)\n",
    "    # y_val = np.reshape(y_val, (y_val.shape[0], 1, y_val.shape[1])).astype(int)\n",
    "\n",
    "# y_val = tf.reshape(y_val, shape=[y_val.shape[0], 1, y_val.shape[1]])\n",
    "\n",
    "# Collapse the depth dimension and converts all non-zero values to 1 and zero values to 0\n",
    "# y_val = tf.cast(tf.reduce_max(y_val, axis=2, keepdims=True) > 0, dtype=tf.int32)\n",
    "\n",
    "# Create test set\n",
    "for batch in test_dataset:\n",
    "    X_test = batch[:,:-future_timesteps,:]\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "\n",
    "    y_test = batch[:,-future_timesteps:,:] >= cutoff\n",
    "    y_test = np.max(y_test, axis=1).astype(int)\n",
    "    # y_test = np.reshape(y_test, (y_test.shape[0], 1, y_test.shape[1])).astype(int)\n",
    "\n",
    "# y_test = tf.reshape(y_test, shape=[y_test.shape[0], 1, y_test.shape[1]])\n",
    "\n",
    "# Collapse the depth dimension and converts all non-zero values to 1 and zero values to 0\n",
    "# y_test = tf.cast(tf.reduce_max(y_test, axis=2, keepdims=True) > 0, dtype=tf.int32)\n",
    "\n",
    "################################# Use for MLP\n",
    "# Flatten 1 and 2 dimensions of X's for multivariate MLP\n",
    "# X_train = np.reshape(X_train, (X_train.shape[0],-1))\n",
    "# X_val = np.reshape(X_val, (X_val.shape[0],-1))\n",
    "# X_test = np.reshape(X_test, (X_test.shape[0],-1))\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (BatchN  (365, 29120)             116480    \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (365, 64)                 1863744   \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (365, 64)                256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (365, 64)                 0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (365, 64)                 4160      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (365, 64)                256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (365, 64)                 0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (365, 80)                 5200      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,990,096\n",
      "Trainable params: 1,931,600\n",
      "Non-trainable params: 58,496\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import regularizers\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Assuming X_train.shape is (443, 4160)\n",
    "# and y_train.shape is (443, 80)\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64, activation='LeakyReLU', input_shape=(X_train.shape[1],),\n",
    "                kernel_regularizer=regularizers.L1L2(l1=1e-4, l2=1e-4),\n",
    "                bias_regularizer=regularizers.L1L2(l1=1e-4, l2=1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(Dense(64, activation='LeakyReLU',\n",
    "                kernel_regularizer=regularizers.L1L2(l1=1e-4, l2=1e-4),\n",
    "                bias_regularizer=regularizers.L1L2(l1=1e-4, l2=1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss = tf.keras.losses.BinaryFocalCrossentropy( apply_class_balancing=True, alpha=.7, gamma=1)\n",
    "model.compile(optimizer=opt, loss=loss, metrics=[keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "\n",
    "# Build and display the model summary\n",
    "model.build(input_shape=X_train.shape)\n",
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3/3 [==============================] - 1s 150ms/step - loss: 1.5140 - precision: 0.1918 - recall: 0.5091 - val_loss: 1.3794 - val_precision: 0.1649 - val_recall: 0.4742\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.2189 - precision: 0.2021 - recall: 0.5354 - val_loss: 1.1431 - val_precision: 0.1599 - val_recall: 0.4433\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.9984 - precision: 0.2014 - recall: 0.5259 - val_loss: 0.9737 - val_precision: 0.1667 - val_recall: 0.4742\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.8447 - precision: 0.2068 - recall: 0.5424 - val_loss: 0.8522 - val_precision: 0.1685 - val_recall: 0.4742\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7507 - precision: 0.2110 - recall: 0.5565 - val_loss: 0.7878 - val_precision: 0.1679 - val_recall: 0.4742\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7059 - precision: 0.2161 - recall: 0.5693 - val_loss: 0.7128 - val_precision: 0.1573 - val_recall: 0.4330\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6410 - precision: 0.2188 - recall: 0.5774 - val_loss: 0.6194 - val_precision: 0.1604 - val_recall: 0.4433\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5702 - precision: 0.2237 - recall: 0.5851 - val_loss: 0.5352 - val_precision: 0.1795 - val_recall: 0.5052\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5053 - precision: 0.2271 - recall: 0.5880 - val_loss: 0.4773 - val_precision: 0.1798 - val_recall: 0.4948\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4633 - precision: 0.2271 - recall: 0.5880 - val_loss: 0.4393 - val_precision: 0.1673 - val_recall: 0.4536\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4248 - precision: 0.2323 - recall: 0.6017 - val_loss: 0.3951 - val_precision: 0.1593 - val_recall: 0.4433\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3909 - precision: 0.2352 - recall: 0.6085 - val_loss: 0.3564 - val_precision: 0.2008 - val_recall: 0.5258\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3682 - precision: 0.2341 - recall: 0.6048 - val_loss: 0.3304 - val_precision: 0.2143 - val_recall: 0.5258\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3512 - precision: 0.2348 - recall: 0.6026 - val_loss: 0.3124 - val_precision: 0.1974 - val_recall: 0.4742\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3351 - precision: 0.2378 - recall: 0.6123 - val_loss: 0.3040 - val_precision: 0.1918 - val_recall: 0.4845\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3286 - precision: 0.2375 - recall: 0.6080 - val_loss: 0.2967 - val_precision: 0.2133 - val_recall: 0.4948\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3230 - precision: 0.2391 - recall: 0.6069 - val_loss: 0.2945 - val_precision: 0.2233 - val_recall: 0.4742\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3180 - precision: 0.2430 - recall: 0.6199 - val_loss: 0.2878 - val_precision: 0.2673 - val_recall: 0.5567\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3115 - precision: 0.2460 - recall: 0.6188 - val_loss: 0.2796 - val_precision: 0.3351 - val_recall: 0.6598\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3072 - precision: 0.2457 - recall: 0.6177 - val_loss: 0.2739 - val_precision: 0.4233 - val_recall: 0.7113\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3015 - precision: 0.2497 - recall: 0.6230 - val_loss: 0.2694 - val_precision: 0.4417 - val_recall: 0.7423\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2961 - precision: 0.2513 - recall: 0.6206 - val_loss: 0.2654 - val_precision: 0.4730 - val_recall: 0.7216\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2941 - precision: 0.2533 - recall: 0.6323 - val_loss: 0.2630 - val_precision: 0.4932 - val_recall: 0.7423\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2887 - precision: 0.2595 - recall: 0.6402 - val_loss: 0.2619 - val_precision: 0.5177 - val_recall: 0.7526\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2868 - precision: 0.2618 - recall: 0.6379 - val_loss: 0.2628 - val_precision: 0.4500 - val_recall: 0.7423\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2832 - precision: 0.2630 - recall: 0.6399 - val_loss: 0.2610 - val_precision: 0.4491 - val_recall: 0.7732\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2813 - precision: 0.2653 - recall: 0.6399 - val_loss: 0.2567 - val_precision: 0.5098 - val_recall: 0.8041\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2791 - precision: 0.2704 - recall: 0.6494 - val_loss: 0.2521 - val_precision: 0.5985 - val_recall: 0.8144\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2761 - precision: 0.2726 - recall: 0.6437 - val_loss: 0.2482 - val_precision: 0.6119 - val_recall: 0.8454\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2753 - precision: 0.2754 - recall: 0.6548 - val_loss: 0.2457 - val_precision: 0.6585 - val_recall: 0.8351\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2696 - precision: 0.2966 - recall: 0.6743 - val_loss: 0.2457 - val_precision: 0.7000 - val_recall: 0.8660\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2682 - precision: 0.2950 - recall: 0.6725 - val_loss: 0.2454 - val_precision: 0.7034 - val_recall: 0.8557\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2663 - precision: 0.3039 - recall: 0.6759 - val_loss: 0.2468 - val_precision: 0.6923 - val_recall: 0.8351\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2654 - precision: 0.3065 - recall: 0.6808 - val_loss: 0.2479 - val_precision: 0.7143 - val_recall: 0.8247\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2630 - precision: 0.3134 - recall: 0.6887 - val_loss: 0.2470 - val_precision: 0.7321 - val_recall: 0.8454\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2640 - precision: 0.3122 - recall: 0.6799 - val_loss: 0.2454 - val_precision: 0.7257 - val_recall: 0.8454\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2600 - precision: 0.3241 - recall: 0.6909 - val_loss: 0.2436 - val_precision: 0.7339 - val_recall: 0.8247\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2576 - precision: 0.3339 - recall: 0.7033 - val_loss: 0.2417 - val_precision: 0.7453 - val_recall: 0.8144\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2561 - precision: 0.3483 - recall: 0.7065 - val_loss: 0.2384 - val_precision: 0.7593 - val_recall: 0.8454\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2545 - precision: 0.3556 - recall: 0.7082 - val_loss: 0.2341 - val_precision: 0.7456 - val_recall: 0.8763\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2514 - precision: 0.3703 - recall: 0.7251 - val_loss: 0.2301 - val_precision: 0.7411 - val_recall: 0.8557\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2508 - precision: 0.3656 - recall: 0.7181 - val_loss: 0.2281 - val_precision: 0.7391 - val_recall: 0.8763\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2444 - precision: 0.3942 - recall: 0.7402 - val_loss: 0.2257 - val_precision: 0.7328 - val_recall: 0.8763\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2437 - precision: 0.3984 - recall: 0.7415 - val_loss: 0.2238 - val_precision: 0.7265 - val_recall: 0.8763\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2416 - precision: 0.4123 - recall: 0.7496 - val_loss: 0.2222 - val_precision: 0.7265 - val_recall: 0.8763\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2397 - precision: 0.4253 - recall: 0.7606 - val_loss: 0.2215 - val_precision: 0.7179 - val_recall: 0.8660\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2379 - precision: 0.4333 - recall: 0.7595 - val_loss: 0.2213 - val_precision: 0.7143 - val_recall: 0.8763\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2370 - precision: 0.4484 - recall: 0.7784 - val_loss: 0.2202 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2342 - precision: 0.4635 - recall: 0.7809 - val_loss: 0.2191 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2304 - precision: 0.4811 - recall: 0.7827 - val_loss: 0.2168 - val_precision: 0.7143 - val_recall: 0.8763\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2278 - precision: 0.4953 - recall: 0.7955 - val_loss: 0.2136 - val_precision: 0.7203 - val_recall: 0.8763\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2239 - precision: 0.5224 - recall: 0.8081 - val_loss: 0.2113 - val_precision: 0.7143 - val_recall: 0.8763\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2231 - precision: 0.5196 - recall: 0.8053 - val_loss: 0.2085 - val_precision: 0.7143 - val_recall: 0.8763\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2200 - precision: 0.5387 - recall: 0.8128 - val_loss: 0.2064 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2187 - precision: 0.5349 - recall: 0.8081 - val_loss: 0.2045 - val_precision: 0.7143 - val_recall: 0.8763\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2136 - precision: 0.5724 - recall: 0.8344 - val_loss: 0.2039 - val_precision: 0.7203 - val_recall: 0.8763\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2168 - precision: 0.5544 - recall: 0.8265 - val_loss: 0.2026 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2119 - precision: 0.5875 - recall: 0.8384 - val_loss: 0.2008 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2099 - precision: 0.5946 - recall: 0.8481 - val_loss: 0.1975 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2065 - precision: 0.6042 - recall: 0.8413 - val_loss: 0.1941 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2044 - precision: 0.6069 - recall: 0.8411 - val_loss: 0.1912 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2015 - precision: 0.6194 - recall: 0.8427 - val_loss: 0.1907 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2026 - precision: 0.6087 - recall: 0.8471 - val_loss: 0.1902 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2003 - precision: 0.6369 - recall: 0.8550 - val_loss: 0.1902 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1965 - precision: 0.6469 - recall: 0.8607 - val_loss: 0.1883 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1963 - precision: 0.6357 - recall: 0.8499 - val_loss: 0.1855 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1901 - precision: 0.6555 - recall: 0.8701 - val_loss: 0.1823 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1924 - precision: 0.6297 - recall: 0.8543 - val_loss: 0.1807 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1885 - precision: 0.6536 - recall: 0.8598 - val_loss: 0.1807 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1863 - precision: 0.6680 - recall: 0.8743 - val_loss: 0.1795 - val_precision: 0.7059 - val_recall: 0.8660\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1864 - precision: 0.6623 - recall: 0.8674 - val_loss: 0.1767 - val_precision: 0.7059 - val_recall: 0.8660\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1828 - precision: 0.6625 - recall: 0.8698 - val_loss: 0.1731 - val_precision: 0.7119 - val_recall: 0.8660\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1793 - precision: 0.6656 - recall: 0.8633 - val_loss: 0.1705 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1785 - precision: 0.6672 - recall: 0.8672 - val_loss: 0.1701 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1767 - precision: 0.6774 - recall: 0.8741 - val_loss: 0.1696 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1747 - precision: 0.6792 - recall: 0.8717 - val_loss: 0.1683 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1758 - precision: 0.6744 - recall: 0.8750 - val_loss: 0.1664 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1745 - precision: 0.6661 - recall: 0.8750 - val_loss: 0.1661 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1727 - precision: 0.6818 - recall: 0.8766 - val_loss: 0.1663 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1714 - precision: 0.6885 - recall: 0.8861 - val_loss: 0.1652 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1695 - precision: 0.6881 - recall: 0.8795 - val_loss: 0.1623 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1651 - precision: 0.6945 - recall: 0.8842 - val_loss: 0.1593 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1633 - precision: 0.6861 - recall: 0.8838 - val_loss: 0.1557 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1584 - precision: 0.7011 - recall: 0.8878 - val_loss: 0.1536 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1572 - precision: 0.6903 - recall: 0.8876 - val_loss: 0.1526 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1567 - precision: 0.6953 - recall: 0.8816 - val_loss: 0.1533 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1566 - precision: 0.6980 - recall: 0.8867 - val_loss: 0.1537 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 88/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1557 - precision: 0.7028 - recall: 0.8926 - val_loss: 0.1516 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 89/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1559 - precision: 0.6853 - recall: 0.8825 - val_loss: 0.1512 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 90/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1560 - precision: 0.6924 - recall: 0.8867 - val_loss: 0.1529 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 91/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1578 - precision: 0.6901 - recall: 0.8860 - val_loss: 0.1539 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 92/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1564 - precision: 0.6992 - recall: 0.8925 - val_loss: 0.1539 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 93/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1570 - precision: 0.6896 - recall: 0.8867 - val_loss: 0.1516 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 94/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1529 - precision: 0.7027 - recall: 0.8885 - val_loss: 0.1491 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 95/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1499 - precision: 0.7014 - recall: 0.8926 - val_loss: 0.1451 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 96/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1460 - precision: 0.7008 - recall: 0.8903 - val_loss: 0.1424 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 97/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1427 - precision: 0.7090 - recall: 0.9009 - val_loss: 0.1403 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 98/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1413 - precision: 0.7065 - recall: 0.8907 - val_loss: 0.1385 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 99/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1396 - precision: 0.7049 - recall: 0.8957 - val_loss: 0.1373 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 100/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1380 - precision: 0.7099 - recall: 0.8935 - val_loss: 0.1363 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 101/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1394 - precision: 0.6973 - recall: 0.8907 - val_loss: 0.1376 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 102/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1409 - precision: 0.7059 - recall: 0.8912 - val_loss: 0.1398 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 103/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1424 - precision: 0.7034 - recall: 0.8935 - val_loss: 0.1417 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 104/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1454 - precision: 0.6990 - recall: 0.8912 - val_loss: 0.1421 - val_precision: 0.7083 - val_recall: 0.8763\n",
      "Epoch 105/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1454 - precision: 0.6975 - recall: 0.8907 - val_loss: 0.1435 - val_precision: 0.7083 - val_recall: 0.8763\n"
     ]
    }
   ],
   "source": [
    "# early stopping\n",
    "callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "# fit model\n",
    "history = model.fit(x=X_train,\n",
    "                    y=y_train,\n",
    "                    validation_data=(X_val,y_val),\n",
    "                    batch_size=128,\n",
    "                    epochs=500,\n",
    "                    verbose=1,\n",
    "                    callbacks=[callback],\n",
    "                    shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x15e1d0550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 46ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.902083\n",
      "Precision: 0.708333\n",
      "Recall: 0.876289\n",
      "F1 score: 0.783410\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       M<4.5       0.97      0.91      0.94       383\n",
      "      M>=4.5       0.71      0.88      0.78        97\n",
      "\n",
      "    accuracy                           0.90       480\n",
      "   macro avg       0.84      0.89      0.86       480\n",
      "weighted avg       0.91      0.90      0.91       480\n",
      "\n",
      "zeroR: 0.9127\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(np.array(y_val).flatten(), y_pred.flatten() >= .5)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(np.array(y_val).flatten(), y_pred.flatten() >= .5)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(np.array(y_val).flatten(), y_pred.flatten() >= .5)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(np.array(y_val).flatten(), y_pred.flatten() >= .5)\n",
    "print('F1 score: %f' % f1)\n",
    "\n",
    "class_names = ['M<4.5', 'M>=4.5']\n",
    "\n",
    "print(classification_report(np.array(y_val).flatten(), y_pred.flatten() >= .5, target_names=class_names))\n",
    "\n",
    "# Calculate the proportion of the majority per row, column combination over all batches\n",
    "majority_prop = np.mean(val >= cutoff, axis=0)[:]\n",
    "\n",
    "# Calculate the complement for values lower than 0.5\n",
    "majority_prop = np.where(majority_prop < 0.5, 1 - majority_prop, majority_prop)\n",
    "zeroR = majority_prop.mean()\n",
    "\n",
    "print(\"zeroR:\", round(zeroR,4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'M<4.5'), Text(0, 1.5, 'M>=4.5')]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "sns.set(rc={'figure.figsize':(5,5)})\n",
    "p = sns.heatmap(confusion_matrix(np.array(y_val).flatten(), y_pred.flatten() >= 0.5), annot=True, fmt='g')\n",
    "p.set_xlabel(\"Predicted\")\n",
    "p.set_ylabel(\"True\")\n",
    "p.xaxis.set_ticklabels(['M<4.5', 'M>=4.5'], ha=\"center\", va=\"center\")\n",
    "p.yaxis.set_ticklabels(['M<4.5', 'M>=4.5'], rotation=0, va=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
