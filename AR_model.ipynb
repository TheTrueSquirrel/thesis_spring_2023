{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 2D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Choose frequency, binsize, longitude, latitude\n",
    "freq = 'M'\n",
    "binsize = 20\n",
    "longitude_W = 134 # minimum is 134\n",
    "longitude_E = 174 # maximum is 174\n",
    "latitude_S = 10 # minimum is 10\n",
    "latitude_N = 60 # minimum is 60\n",
    "\n",
    "# load earthquake data for defined area\n",
    "data = pd.read_csv('data/Japan_10_60_134_174_1973_2023_V2.csv', index_col=0)\n",
    "data['Time'] = pd.to_datetime(data.Time)\n",
    "data = data[(data.Longitude >= longitude_W) & (data.Longitude <= longitude_E) & (data.Latitude >= latitude_S) & (data.Latitude <= latitude_N)]\n",
    "data.set_index('Time', inplace=True)\n",
    "df = data.sort_index()\n",
    "\n",
    "# Bin the longitude and latitude values into 2x2 degree bins\n",
    "df['Longitude_bin'] = pd.cut(df['Longitude'], bins=np.arange(longitude_W, longitude_E+1, binsize))  # Change bin size to 2 degrees\n",
    "df['Latitude_bin'] = pd.cut(df['Latitude'], bins=np.arange(latitude_S, latitude_N+1, binsize))  # Change bin size to 2 degrees\n",
    "\n",
    "# Group the data by longitude bin, latitude bin, depth bin, and day, and compute the maximum magnitude within each group\n",
    "grouped = df.groupby(['Longitude_bin', 'Latitude_bin', pd.Grouper(freq=freq, level=\"Time\")]).max()['Magnitude']\n",
    "grouped = grouped.unstack().fillna(0)\n",
    "\n",
    "# Reshape the resulting data into a tensor with shape (1, time, depth, longitude, latitude)\n",
    "time = len(grouped.columns)\n",
    "longitude = len(grouped.index.levels[0])\n",
    "latitude = len(grouped.index.levels[1])\n",
    "tensor = np.zeros((time, longitude, latitude))\n",
    "\n",
    "for t in range(time):\n",
    "    tensor[t, :, :] = grouped.iloc[:, t].values.reshape(longitude, latitude)\n",
    "\n",
    "# Rotate dimensions corresponding to 20 and 25, 90 degrees anti-clockwise\n",
    "tensor = np.transpose(tensor, axes=(0, 2, 1))\n",
    "tensor = np.flip(tensor, axis=1)\n",
    "\n",
    "# Print the shape of the resulting tensor\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['time'] = data.index\n",
    "data.sort_index(inplace=True)\n",
    "data = data.resample(\"D\", on='time').max().fillna(0)\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise data (tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Choose a timestep to plot (e.g. the first timestep)\n",
    "timestep = 5\n",
    "\n",
    "# Extract the data for the chosen timestep from the tensor\n",
    "\n",
    "time_slice = tensor[timestep, :, :]\n",
    "\n",
    "# Create a heatmap plot of the data using Seaborn\n",
    "sns.set(rc={'figure.figsize':(4.8,6)})\n",
    "sns.heatmap(time_slice, cmap='viridis', vmin=-1, vmax=10, linewidths=0.5, linecolor='grey', annot=False, xticklabels=grouped.index.levels[0], yticklabels=grouped.index.levels[1])\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "plt.title(f'Earthquake magnitudes at timestep {timestep}')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape tensor into matrix\n",
    "matrix = np.reshape(tensor, (tensor.shape[0], -1))\n",
    "df_transformed = pd.DataFrame(matrix).set_index(grouped.T.index)\n",
    "\n",
    "active_column = df_transformed.sum(axis=0).argmax()\n",
    "\n",
    "# print column number with highest sum\n",
    "print(\"column with highest sum of magnitudes:\", active_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set(rc={'figure.figsize':(10,3)})\n",
    "plot = sns.lineplot(data=df_transformed[active_column], linewidth = .2, legend=False)\n",
    "plot.set_xlabel(\"Time in months\")\n",
    "plot.set_ylabel(\"Magnitude\")\n",
    "plot.set_title(\"Earthquakes for most active column\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in cv.split(df_transformed[active_column].values):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    print(df_transformed[active_column][train_index].values)\n",
    "    print(df_transformed[active_column][test_index].values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement AutoRegressive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Choose lookback-window with train_size (multiple of freq)\n",
    "train_size = 10\n",
    "windowsize = 1\n",
    "lags = 10\n",
    "total_splits = len(df_transformed)-train_size\n",
    "# test_size is number of timewindows to predict into the future (is 1)\n",
    "test_size = 1\n",
    "mag = 6\n",
    "\n",
    "\n",
    "# Generate split\n",
    "train, val_test = train_test_split(df_transformed[active_column].values, test_size=.4, shuffle=False)\n",
    "val, test = train_test_split(val_test, test_size=.5, shuffle=False)\n",
    "\n",
    "train = df_transformed[active_column].values\n",
    "\n",
    "cv = TimeSeriesSplit(n_splits=total_splits, max_train_size=train_size ,test_size=test_size)\n",
    "\n",
    "model = AutoReg(train, lags=lags)\n",
    "model_fit = model.fit()\n",
    "# print('Coefficients: %s' % model_fit.params)\n",
    "\n",
    "# make predictions\n",
    "predictions = model_fit.predict(start=len(train), end=len(train)+len(val)-1, dynamic=False)\n",
    "# forecast = model_fit.forecast(steps=1)\n",
    "#print('true:', val[0:10], 'prediction:', forecast[:])\n",
    "print('true:', val[:], 'prediction:', predictions[:])\n",
    "\n",
    "cm = confusion_matrix(val >= mag, predictions >= mag)\n",
    "class_names = ['M<6','M>=6']\n",
    "\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(val >= mag, predictions >= mag, target_names=class_names))\n",
    "\n",
    "prop = (val >= mag).mean()\n",
    "\n",
    "majority_prop = np.where(prop < 0.5, 1 - prop, prop)\n",
    "zeroR = majority_prop.mean()\n",
    "\n",
    "print(\"zeroR:\", round(zeroR,4))\n",
    "\"\"\"\n",
    "# Generate split\n",
    "cv = TimeSeriesSplit(n_splits=total_splits, max_train_size=train_size ,test_size=test_size)\n",
    "\n",
    "mse_total = 0\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# Train the model and safe predictions\n",
    "for train_index, test_index in cv.split(df_transformed[active_column].values):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "    # fit an ARIMA model\n",
    "    model = AutoReg(df_transformed[active_column][train_index].values, lags=10)  # (p, d, q) order\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    # forecast next week's magnitudes\n",
    "    forecast = model_fit.forecast(steps=test_size)\n",
    "    # print('true:', data[test_index][0], 'prediction:', round(forecast[0],1))\n",
    "\n",
    "    # evaluate model performance\n",
    "    mse = mean_squared_error(df_transformed[active_column][test_index].values, forecast)\n",
    "    mse_total += mse\n",
    "    #print('inermediate MSE:', mse)\n",
    "\n",
    "    if df_transformed[active_column][test_index][0] >= mag:\n",
    "        y_true.append(1)\n",
    "        if forecast[0] >= mag:\n",
    "            y_pred.append(1)\n",
    "            TP += 1\n",
    "        if forecast[0] < mag:\n",
    "            FN += 1\n",
    "            y_pred.append(0)\n",
    "    if df_transformed[active_column][test_index][0] < mag:\n",
    "        y_true.append(0)\n",
    "        if forecast[0] >= mag:\n",
    "            y_pred.append(1)\n",
    "            FP += 1\n",
    "        if forecast[0] < mag:\n",
    "            y_pred.append(0)\n",
    "            TN += 1\n",
    "\n",
    "# Evaluate the performance\n",
    "acc = (TP+TN) / (TP+TN+FP+FN)\n",
    "precision = TP / (TP+FP)\n",
    "recall = TP / (TP+FN)\n",
    "specificity = TN / (TN+FP)\n",
    "\n",
    "print('accuracy:', acc)\n",
    "print('precision:', precision)\n",
    "print('recall:', recall)\n",
    "print('specificity:', specificity)\n",
    "print('Mean Absolute Error:', mse_total/total_splits)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "class_names = ['M<5','M>=5']\n",
    "\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "sns.set(rc={'figure.figsize':(20,5)})\n",
    "plot = sns.lineplot(data=dataset, linewidth = .2, legend=False)\n",
    "plot.set_xlabel(\"Time in months\")\n",
    "plot.set_ylabel(\"Magnitude\")\n",
    "plot.set_title(\"Earthquakes for specified spatial bin\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualise autocorrelation (ACF) to define MA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### autocorrelation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "sns.set(rc={'figure.figsize':(10,3)})\n",
    "autocorrelation_plot(df_transformed[active_column])\n",
    "plt.ylim(-.2, .2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "plot_acf(df_transformed[active_column], lags=500)\n",
    "plt.ylim(-.2, .2)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize PACF to define AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacf_val = pacf(data)\n",
    "plt.bar(range(0,len(pacf_val)),pacf_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistance model (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "subregion = df_transformed[active_column]\n",
    "\n",
    "true = subregion[:-1]\n",
    "pred = subregion.shift(-1)[:-1]\n",
    "\n",
    "mse = mean_squared_error(true, pred)\n",
    "print(\"RMSE:\",sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8acd2a4c40bb06440d03e583eeea35c6596324a3385dafe16353bbc1939be192"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
